{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/alicegao/work/psi-lab-sandbox/rna_ss/data_processing/rnafold_mini_data/data/rand_seqs_var_len_sample_mfe_10_50_100.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble_diversity</th>\n",
       "      <th>free_energy</th>\n",
       "      <th>len</th>\n",
       "      <th>mfe_frequency</th>\n",
       "      <th>one_idx</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.48</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.648747</td>\n",
       "      <td>([0, 1, 2, 10, 11, 12], [12, 11, 10, 2, 1, 0])</td>\n",
       "      <td>GACCGCUAAUGUCGAAUCU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.42</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.705145</td>\n",
       "      <td>([2, 3, 4, 7, 8, 9, 10, 15, 16, 17, 18, 21, 22...</td>\n",
       "      <td>ACCUGAUUACCAAACGGUGUCCAGAAAGCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.84</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>46</td>\n",
       "      <td>0.204397</td>\n",
       "      <td>([7, 8, 9, 10, 11, 18, 19, 20, 32, 33, 34, 40,...</td>\n",
       "      <td>CUCAAAUUCCAUUAUACACGAUAUAUUCUCGCUCGGCACCGUGGAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.35</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.864861</td>\n",
       "      <td>([0, 1, 2, 3, 10, 11, 12, 13], [13, 12, 11, 10...</td>\n",
       "      <td>CUGCUAACGCGCAGCAAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.75</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.147935</td>\n",
       "      <td>([5, 6, 7, 8, 11, 12, 16, 17, 20, 21, 22, 23, ...</td>\n",
       "      <td>GUCUAGCUUGAGAACUUUGAAGGCGCACCGUGUCAAAGCCGUGUAUCG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ensemble_diversity  free_energy  len  mfe_frequency  \\\n",
       "0                2.48         -1.1   19       0.648747   \n",
       "1                1.42         -6.0   30       0.705145   \n",
       "2                3.84         -5.3   46       0.204397   \n",
       "3                1.35         -4.0   18       0.864861   \n",
       "4               13.75         -7.1   48       0.147935   \n",
       "\n",
       "                                             one_idx  \\\n",
       "0     ([0, 1, 2, 10, 11, 12], [12, 11, 10, 2, 1, 0])   \n",
       "1  ([2, 3, 4, 7, 8, 9, 10, 15, 16, 17, 18, 21, 22...   \n",
       "2  ([7, 8, 9, 10, 11, 18, 19, 20, 32, 33, 34, 40,...   \n",
       "3  ([0, 1, 2, 3, 10, 11, 12, 13], [13, 12, 11, 10...   \n",
       "4  ([5, 6, 7, 8, 11, 12, 16, 17, 20, 21, 22, 23, ...   \n",
       "\n",
       "                                                seq  \n",
       "0                               GACCGCUAAUGUCGAAUCU  \n",
       "1                    ACCUGAUUACCAAACGGUGUCCAGAAAGCC  \n",
       "2    CUCAAAUUCCAUUAUACACGAUAUAUUCUCGCUCGGCACCGUGGAG  \n",
       "3                                CUGCUAACGCGCAGCAAU  \n",
       "4  GUCUAGCUUGAGAACUUUGAAGGCGCACCGUGUCAAAGCCGUGUAUCG  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnaFeDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(RnaFeDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "#         pass\n",
    "        return ['rna_fe.dataset']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        data_list = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            seq = row['seq']\n",
    "            fe = row['free_energy']\n",
    "            one_idx = row['one_idx']\n",
    "            \n",
    "            # use integer encoding for now\n",
    "            seq = seq.upper().replace('A', '1').replace('C', '2').replace('G', '3').replace('T', '4').replace('U', '4').replace('N', '0')\n",
    "            node_features = np.asarray(list(map(int, list(seq))), dtype=np.int16)\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)  # FIXME dtype\n",
    "            \n",
    "            # build edges\n",
    "            edge_from = []\n",
    "            edge_to = []\n",
    "            # chain - undirected edge for now\n",
    "            node_left = range(0, len(seq) - 1)\n",
    "            node_right = range(1, len(seq))\n",
    "            edge_from.extend(node_left)\n",
    "            edge_to.extend(node_right)\n",
    "            edge_from.extend(node_right)\n",
    "            edge_to.extend(node_left)\n",
    "            # pair matrix - undirected edge \n",
    "            for idx_left, idx_right in zip(one_idx[0], one_idx[1]):\n",
    "                edge_from.append(idx_left)\n",
    "                edge_to.append(idx_right)\n",
    "                edge_from.append(idx_right)\n",
    "                edge_to.append(idx_left)\n",
    "            edge_index = torch.tensor([edge_from, edge_to], dtype=torch.long)\n",
    "            \n",
    "            # target value\n",
    "            assert not np.isnan(fe)\n",
    "            y = fe\n",
    "            \n",
    "            # make data point\n",
    "            data = Data(x=node_features, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RnaFeDataset(root=os.path.join(os.getcwd(), 'dataset/rna_1/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 10, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:80]\n",
    "val_dataset = dataset[80:90]\n",
    "test_dataset = dataset[90:]\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 5\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.act = torch.nn.ReLU()\n",
    "#         self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_lin = torch.nn.Linear(in_channels + out_channels, out_channels, bias=False)\n",
    "        self.update_act = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "#         print('sage, before', x_j.shape)\n",
    "        x_j = self.lin(x_j)\n",
    "#         print('sage, after lin', x_j.shape)\n",
    "        x_j = self.act(x_j)\n",
    "#         print('sage, after act', x_j.shape)\n",
    "        \n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        \n",
    "#         print('sage, before update', new_embedding.shape)\n",
    "        new_embedding = self.update_lin(new_embedding)\n",
    "        new_embedding = self.update_act(new_embedding)\n",
    "#         print('sage, after update', new_embedding.shape)\n",
    "        \n",
    "        return new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 5\n",
    "n_hid = 10\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(embed_dim, n_hid)\n",
    "#         self.pool1 = TopKPooling(n_hid, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(n_hid, n_hid)\n",
    "#         self.pool2 = TopKPooling(n_hid, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(n_hid, n_hid)\n",
    "#         self.pool3 = TopKPooling(n_hid, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=5, embedding_dim=embed_dim)\n",
    "        self.lin1 = torch.nn.Linear(n_hid * 2, n_hid)\n",
    "        self.lin2 = torch.nn.Linear(n_hid, n_hid//2)\n",
    "        self.lin3 = torch.nn.Linear(n_hid//2, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(n_hid)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(n_hid//2)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()        \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)    \n",
    "#         print('after embedding', x.shape)\n",
    "#         print(x[0, :])\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "#         print('after conv1', x.shape)\n",
    "#         print(x[0, :])\n",
    "\n",
    "        #x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "#         x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "#         print('after conv2', x.shape)\n",
    "#         print(x[0, :])\n",
    "     \n",
    "        #x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "#         x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "\n",
    "        #x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "#         x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)      \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "#         x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "        x = self.lin3(x).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "# crit = torch.nn.BCELoss()\n",
    "crit = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "\n",
    "#     loss_all = 0\n",
    "#     for data in train_loader:\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         label = data.y.to(device)\n",
    "#         loss = crit(output, label)\n",
    "#         loss.backward()\n",
    "#         loss_all += data.num_graphs * loss.item()\n",
    "#         optimizer.step()\n",
    "#     return loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "            labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    labels = np.hstack(labels)\n",
    "    \n",
    "    corr, pval = spearmanr(labels, predictions)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 43.31988, Train corr: 0.28330, Val corr: 0.81709, Test corr: 0.38298\n",
      "Epoch: 001, Loss: 31.71949, Train corr: 0.41872, Val corr: 0.83538, Test corr: 0.39514\n",
      "Epoch: 002, Loss: 27.84745, Train corr: 0.46341, Val corr: 0.78660, Test corr: 0.54104\n",
      "Epoch: 003, Loss: 28.94456, Train corr: 0.52783, Val corr: 0.84758, Test corr: 0.63830\n",
      "Epoch: 004, Loss: 26.15729, Train corr: 0.55678, Val corr: 0.89026, Test corr: 0.69301\n",
      "Epoch: 005, Loss: 24.83331, Train corr: 0.57378, Val corr: 0.94514, Test corr: 0.72949\n",
      "Epoch: 006, Loss: 28.18099, Train corr: 0.57836, Val corr: 0.89026, Test corr: 0.70517\n",
      "Epoch: 007, Loss: 24.37705, Train corr: 0.59364, Val corr: 0.93294, Test corr: 0.70517\n",
      "Epoch: 008, Loss: 28.49526, Train corr: 0.60867, Val corr: 0.89026, Test corr: 0.69301\n",
      "Epoch: 009, Loss: 26.67515, Train corr: 0.62437, Val corr: 0.93294, Test corr: 0.63222\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "#     loss = train()\n",
    "\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y.to(device)\n",
    "        loss = crit(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    loss = loss_all / len(train_dataset)\n",
    "\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)    \n",
    "    test_acc = evaluate(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train corr: {:.5f}, Val corr: {:.5f}, Test corr: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check in to github\n",
    "# TODO how to force re-process dataset?\n",
    "# add back pooling\n",
    "# take into account length? - mean+max might not work\n",
    "# more data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
