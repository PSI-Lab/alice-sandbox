{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils.utils_model as us1\n",
    "from model_utils.util_s1_long_seq_bb_method import predict_long_seq_wrapper\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-slide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mineral-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_joined_df(df1, df2):\n",
    "    \n",
    "    def check_arr_eq(arr1, arr2):\n",
    "        arr1 = np.sort(np.asarray(arr1))\n",
    "        arr2 = np.sort(np.asarray(arr2))\n",
    "        np.testing.assert_array_almost_equal(arr1, arr2)\n",
    "    \n",
    "    df_check = pd.merge(df1, pd.DataFrame(df2), on=['bb_x', 'bb_y', 'siz_x', 'siz_y'], how='outer')\n",
    "    assert len(df1) == len(df2)\n",
    "    assert len(df1) == len(df_check)\n",
    "    \n",
    "    for _, row in df_check.iterrows():\n",
    "        if 'prob_sm_x' in row.keys() and 'prob_sm_y' in row.keys():\n",
    "            check_arr_eq(row['prob_sm_x'], row['prob_sm_y'])\n",
    "        if 'prob_sl_x' in row.keys() and 'prob_sl_y' in row.keys():   \n",
    "            check_arr_eq(row['prob_sl_x'], row['prob_sl_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-studio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "altered-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading know version v1.0 with params {'num_filters': [32, 32, 64, 64, 64, 128, 128], 'filter_width': [9, 9, 9, 9, 9, 9, 9], 'dropout': 0.0}\n"
     ]
    }
   ],
   "source": [
    "predictor_s1 = us1.Predictor('v1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exotic-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len 200\n",
    "# seq = 'ACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGCGACGACAGCGATGATGGCGATAAAATTAGGCGCTAGCCCGGATGGAGGGGGAGGAGGAACCCCCTCTGATGCTGATGATCGATATGGCGATAAAATTAGGCGCTAGCCCGGATGGAGGGGGAGGAGGAACCCCCTCTGATGCTGATGATCGAT'\n",
    "\n",
    "\n",
    "# # len 56\n",
    "# seq = 'ACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# len 80\n",
    "seq = 'ACGATGACGATAGACGCGTATTAGACGAGACGGACGTAGACGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# # len 60\n",
    "# seq = 'ACGATGACGATAGAAGCACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# # len 112\n",
    "# seq = 'ACGATGACGATAGACGCGACGACACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGAAGCGATGACGATGACGATAGACGACGACAGCGA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "skilled-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-capture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cognitive-escape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/work/psi-lab-sandbox/meetings/2021_02_02/model_utils/utils_model.py:958: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yp = self.model(torch.tensor(de.x_torch))\n"
     ]
    }
   ],
   "source": [
    "# non-split (original interface)\n",
    "stem_1, iloop_1, hloop_1 = predictor_s1.predict_bb(seq, threshold=0.1, topk=1, perc_cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-better",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedicated-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input region: 0-58, 0-58\n",
      "Output region: 0-30, 0-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/work/psi-lab-sandbox/meetings/2021_02_02/model_utils/utils_model.py:837: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yp = self.model(torch.tensor(de.x_torch))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting array output range: 0-30, 0-30\n",
      "Input region: 0-58, 2-80\n",
      "Output region: 0-30, 30-60\n",
      "Selecting array output range: 0-30, 28-58\n",
      "Input region: 0-58, 32-80\n",
      "Output region: 0-30, 60-80\n",
      "Selecting array output range: 0-30, 28-48\n",
      "Input region: 2-80, 0-58\n",
      "Output region: 30-60, 0-30\n",
      "Selecting array output range: 28-58, 0-30\n",
      "Input region: 2-80, 2-80\n",
      "Output region: 30-60, 30-60\n",
      "Selecting array output range: 28-58, 28-58\n",
      "Input region: 2-80, 32-80\n",
      "Output region: 30-60, 60-80\n",
      "Selecting array output range: 28-58, 28-48\n",
      "Input region: 32-80, 0-58\n",
      "Output region: 60-80, 0-30\n",
      "Patch fully contained in lower triangle matrix, skip.\n",
      "Input region: 32-80, 2-80\n",
      "Output region: 60-80, 30-60\n",
      "Selecting array output range: 28-48, 28-58\n",
      "Input region: 32-80, 32-80\n",
      "Output region: 60-80, 60-80\n",
      "Selecting array output range: 28-48, 28-48\n"
     ]
    }
   ],
   "source": [
    "# split (long sequence interface, array method)\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=28, trim_size=28)\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=40, trim_size=28)\n",
    "\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=80, trim_size=28)\n",
    "\n",
    "stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "                                                         patch_size=30)\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italian-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working for now, see README\n",
    "\n",
    "# # split (long sequence interface, bounding box method)\n",
    "# stem_3, iloop_3, hloop_3 = predict_long_seq_wrapper(seq, patch_size=100, predictor_s1=predictor_s1, \n",
    "#                                                     threshold=0.1, topk=1, perc_cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-longer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-cooperation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hearing-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 23\n"
     ]
    }
   ],
   "source": [
    "# print(len(stem_1), len(stem_2), len(stem_3))\n",
    "print(len(stem_1), len(stem_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "billion-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 34\n"
     ]
    }
   ],
   "source": [
    "# print(len(iloop_1), len(iloop_2), len(iloop_3))\n",
    "print(len(iloop_1), len(iloop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ethical-poetry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "# print(len(hloop_1), len(hloop_2), len(hloop_3))\n",
    "print(len(hloop_1), len(hloop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "raised-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(stem_1), pd.DataFrame(stem_2))\n",
    "# check_joined_df(pd.DataFrame(stem_1), pd.DataFrame(stem_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "revised-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(iloop_1), pd.DataFrame(iloop_2))\n",
    "# check_joined_df(pd.DataFrame(iloop_1), pd.DataFrame(iloop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cognitive-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(hloop_1), pd.DataFrame(hloop_2))\n",
    "# check_joined_df(pd.DataFrame(hloop_1), pd.DataFrame(hloop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-interval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-belgium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-obligation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "focal-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "funky-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# de = us1.SeqPairEncoder(seq_1, seq_2)\n",
    "de = us1.DataEncoder('ACGT')\n",
    "yp = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cubic-missouri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6912e-04, 9.7935e-05, 1.0809e-03, 2.5290e-02],\n",
       "        [9.7002e-05, 1.0694e-04, 5.3612e-03, 1.3337e-02],\n",
       "        [6.5571e-04, 2.1104e-03, 2.2309e-02, 6.3060e-02],\n",
       "        [3.2504e-03, 2.5612e-03, 1.9993e-02, 1.4175e-02]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp['stem_on'][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "administrative-graduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "de = us1.DataEncoder('NNACGT')\n",
    "yp2 = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "romance-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0001, 0.0013, 0.0010, 0.0088],\n",
       "        [0.0009, 0.0027, 0.0013, 0.0021],\n",
       "        [0.0004, 0.0033, 0.0012, 0.0026],\n",
       "        [0.0030, 0.0008, 0.0019, 0.0020]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp2['stem_on'][0, 0, 2:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-shaft",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "separate-retailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "de = us1.SeqPairEncoder('ACGT', 'AAACGT')\n",
    "# de = us1.DataEncoder('ACGT')\n",
    "yp = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-parish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-garbage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
