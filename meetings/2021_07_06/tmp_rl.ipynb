{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6c01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint\n",
    "from itertools import count\n",
    "from collections import namedtuple, deque\n",
    "from sklearn.metrics import f1_score\n",
    "from utils.util_global_struct import process_bb_old_to_new\n",
    "from utils.rna_ss_utils import arr2db, one_idx2arr, compute_fe\n",
    "from utils.inference_s2 import Predictor, process_row_bb_combo, stem_bbs2arr\n",
    "from utils_s2_tree_search import bb_conflict\n",
    "from utils.misc import add_column\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83746b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug dataset\n",
    "df = pd.read_pickle('../2021_06_22/data/data_len60_test_1000_s1_stem_bb_combos_s1s100.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0367d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleSeqEncoder(object):\n",
    "    DNA_ENCODING = np.asarray([[0, 0, 0, 0],\n",
    "                               [1, 0, 0, 0],\n",
    "                               [0, 1, 0, 0],\n",
    "                               [0, 0, 1, 0],\n",
    "                               [0, 0, 0, 1]])\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _encode_seq(self, seq):\n",
    "        seq = seq.upper().replace('A', '1').replace('C', '2').replace('G', '3').replace('T', '4').replace('U',\n",
    "                                                                                                          '4').replace(\n",
    "            'N', '0')\n",
    "        x = np.asarray([int(x) for x in list(seq)])\n",
    "        x = self.DNA_ENCODING[x.astype('int8')]\n",
    "        return x\n",
    "\n",
    "    def tile_and_stack(self, x):\n",
    "        assert len(x.shape) == 2\n",
    "        assert x.shape[1] == 4\n",
    "        l = x.shape[0]\n",
    "        x1 = x[:, np.newaxis, :]\n",
    "        x2 = x[np.newaxis, :, :]\n",
    "        x1 = np.repeat(x1, l, axis=1)\n",
    "        x2 = np.repeat(x2, l, axis=0)\n",
    "        return np.concatenate([x1, x2], axis=2)\n",
    "\n",
    "    def encode_single(self, seq):\n",
    "        x = self._encode_seq(seq)\n",
    "        x = self.tile_and_stack(x)\n",
    "        return x  # TODO LxLx4?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9bcde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_seq_enc = SingleSeqEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994db585",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoundingBox = namedtuple(\"BoundingBox\", ['bb_x', 'bb_y', 'siz_x', 'siz_y'])\n",
    "\n",
    "DataExample = namedtuple('DataExample', \n",
    "                        ('seq', 'seq_arr', 'bbs', 'bb_arrs', 'bb_conflict'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AllDataExamples(object):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.data = dict()\n",
    "        \n",
    "        # reindex to make sure df idx is sequential \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        for data_idx, row in df.iterrows():\n",
    "            seq = row.seq\n",
    "            \n",
    "            if data_idx % 100 == 0:\n",
    "                print(data_idx)\n",
    "            \n",
    "            # bbs\n",
    "            df_stem = pd.DataFrame(row.pred_stem_bb)\n",
    "            # we use df index, make sure it's contiguous\n",
    "            assert df_stem.iloc[-1].name == len(df_stem) - 1\n",
    "            bbs = {}\n",
    "            for idx, r in df_stem.iterrows():\n",
    "                bbs[idx] = BoundingBox(bb_x=r['bb_x'],\n",
    "                                       bb_y=r['bb_y'],\n",
    "                                       siz_x=r['siz_x'],\n",
    "                                       siz_y=r['siz_y'])\n",
    "            \n",
    "            # list of arr\n",
    "            bb_arrs = {bb_id: stem_bbs2arr([bb], len(seq)) for bb_id, bb in bbs.items()}\n",
    "            # bb conflict arr\n",
    "            bb_conflict_arr = np.zeros((len(bbs), len(bbs)))\n",
    "            for i in range(len(bbs)):\n",
    "                for j in range(i, len(bbs)):  # only need to go through half\n",
    "                    if bb_conflict(bbs[i], bbs[j]):\n",
    "                        bb_conflict_arr[i, j] = 1\n",
    "                        bb_conflict_arr[j, i] = 1\n",
    "            # seq\n",
    "            seq = row.seq\n",
    "            seq_arr = single_seq_enc.encode_single(seq)\n",
    "            \n",
    "            # add to data\n",
    "            self.data[data_idx] = DataExample(seq=seq,\n",
    "                                        seq_arr=seq_arr,\n",
    "                                        bbs=bbs,\n",
    "                                        bb_arrs=bb_arrs,\n",
    "                                        bb_conflict=bb_conflict_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813798f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30710ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.random.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e188ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_bb_ids(bb_id_inc, bb_id_next, valid_bb_ids, bb_conflict):\n",
    "    # bb_id_inc: list of IDs included\n",
    "    # bb_id_next: ID of bb to be included next\n",
    "    # valid_bb_ids: list of IDs, current list of valid bbs (contains bb_id_next)\n",
    "    # bb_conflict: NxN binary matrix with 1 indicating conflit\n",
    "    \n",
    "    # check\n",
    "    assert bb_id_next in valid_bb_ids\n",
    "    \n",
    "    # we're removing invalid IDs from valid_bb_ids due to the inclusion of bb_id_next\n",
    "    id_conflict = np.where(bb_conflict[bb_id_next, :])[0]\n",
    "    new_valid_bb_ids = [i for i in valid_bb_ids if i not in id_conflict]\n",
    "    \n",
    "    return new_valid_bb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9a581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b48099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition = namedtuple('Transition',\n",
    "#                         ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('example_id', 'bb_id_inc', 'bbs_inc_arr', 'valid_bb_ids', 'bb_id_next', 'reward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456885f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, h=60, w=60):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(10, 16, kernel_size=5, stride=2)  # input ch = 10 = 8 + 1 + 1\n",
    "#         self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "#         self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "#         self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.out = nn.Linear(linear_input_size, 1)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        return self.out(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e190b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = ValueNetwork(60, 60)\n",
    "target_net = ValueNetwork(60, 60)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6909b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a6f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_all_actions(seq_arr, inc_bbs_arr, next_bbs_arrs, n_actions):\n",
    "    seq_arr = np.tile(seq_arr[np.newaxis, :, :, :], [n_actions, 1, 1, 1])  # kxLxLx8\n",
    "    inc_bbs_arr = np.tile(inc_bbs_arr[np.newaxis, :, :, np.newaxis], [n_actions, 1, 1, 1])  # kxLxLx8\n",
    "    \n",
    "    # FIXME unify data format\n",
    "    if len(next_bbs_arrs[0].shape) == 3:\n",
    "        next_bbs_arrs = [x[np.newaxis, :, :, :] for x in next_bbs_arrs]\n",
    "    elif len(next_bbs_arrs[0].shape) == 2:\n",
    "        next_bbs_arrs = [x[np.newaxis, :, :, np.newaxis] for x in next_bbs_arrs]\n",
    "    else:\n",
    "        raise ValueError\n",
    "    next_bbs_arrs = np.concatenate(next_bbs_arrs, axis=0)\n",
    "    \n",
    "    batch_data = np.concatenate([seq_arr, inc_bbs_arr, next_bbs_arrs], axis=3)  # kxLxLx10\n",
    "    batch_data = torch.from_numpy(batch_data).float()\n",
    "    return batch_data.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(seq_arr, inc_bbs_arr, next_bbs_arrs):  # works on a single example\n",
    "    # seq_arr: LxLx4\n",
    "    # inc_bbs_arr: LxLx1\n",
    "    # next_bbs_arrs: list of k items: LxLx1\n",
    "    \n",
    "    # TODO check dimensions\n",
    "    \n",
    "    \n",
    "    n_actions = len(next_bbs_arrs)\n",
    "    next_bbs_arrs = [x[np.newaxis, :, :, np.newaxis] for x in next_bbs_arrs]\n",
    "    next_bbs_arrs = np.concatenate(next_bbs_arrs, axis=0)\n",
    "    \n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        np.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # predict on all actions as a batch\n",
    "            # kxLxLx6\n",
    "            batch_data = encode_all_actions(seq_arr, inc_bbs_arr, next_bbs_arrs, n_actions)\n",
    "            pred = policy_net(batch_data)  # TODO check dimension kx1?\n",
    "            # index of action following greedy policy\n",
    "            idx_action = pred.argmax(0)  # argmax along dim=0 (actions)\n",
    "            \n",
    "#             # t.max(1) will return largest column value of each row.\n",
    "#             # second column on max result is index of where max element was\n",
    "#             # found, so we pick action with the larger expected reward.\n",
    "#             return policy_net(state).max(1)[1].view(1, 1)\n",
    "        return idx_action\n",
    "    else:\n",
    "        return np.random.randint(0, n_actions)  # [0, n_actions)\n",
    "#         return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b82494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)  # list of transitions\n",
    "    \n",
    "    # Compute Q(s_t, a)\n",
    "    # running all examples as a single batch, since we only need to evaluate one action per example\n",
    "    state_action_batch = []\n",
    "    for transition in transitions:\n",
    "        example_id = transition.example_id\n",
    "        data_example = all_data_examples.data[example_id]\n",
    "        seq_arr = data_example.seq_arr\n",
    "        bb_arr_next = data_example.bb_arrs[transition.bb_id_next]\n",
    "        data = np.concatenate([seq_arr, \n",
    "                               transition.bbs_inc_arr[:, :, np.newaxis],\n",
    "                               bb_arr_next[:, :, np.newaxis]], axis=2)  # LxLx10\n",
    "        data = data[np.newaxis, :, :, :]  # 1xLxLx10\n",
    "        state_action_batch.append(data)\n",
    "    state_action_batch = np.concatenate(state_action_batch, axis=0)  # shape: batch x h x w x channel\n",
    "    state_action_values = policy_net(torch.from_numpy(state_action_batch).float().permute(0, 3, 1, 2))  # torch expects batch x channel x h x w\n",
    "    \n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # next state value: take max over all valid actions at t+2\n",
    "    # runnin each example as their own batch, since we'll be evaluating all valid actions per example\n",
    "    # in the future we can combine different examples and make it more efficient\n",
    "    # also deal with cases where t+1 is the final state, set to 0 otherwise\n",
    "    expected_state_action_values = torch.zeros(len(transitions))\n",
    "    for idx_val, transition in enumerate(transitions):\n",
    "        example_id = transition.example_id\n",
    "        data_example = all_data_examples.data[example_id]\n",
    "        seq_arr = data_example.seq_arr\n",
    "        bp_arr_t1 = transition.bbs_inc_arr + data_example.bb_arrs[transition.bb_id_next]\n",
    "        # find all valid actions from t1 to t2\n",
    "        bb_id_inc_t1 = transition.bb_id_inc + [transition.bb_id_next]\n",
    "        valid_bb_ids = find_valid_bb_ids(transition.bb_id_inc, \n",
    "                                         transition.bb_id_next, \n",
    "                                         transition.valid_bb_ids, \n",
    "                                         data_example.bb_conflict)\n",
    "        if len(valid_bb_ids) == 0:  # no valid action after t+1, i.e. final state\n",
    "            pass  # default is 0\n",
    "        else:\n",
    "            batch_data = encode_all_actions(seq_arr, \n",
    "                                            bp_arr_t1, \n",
    "                                            [data_example.bb_arrs[bb_id] for bb_id in valid_bb_ids],\n",
    "                                           len(valid_bb_ids))\n",
    "            next_state_action_values = target_net(batch_data)\n",
    "            next_state_value = next_state_action_values.max()\n",
    "            expected_state_action_values[idx_val] = (next_state_value * GAMMA) + transition.reward\n",
    "    \n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)  # TODO do we need clamping?\n",
    "    optimizer.step()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb41a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_examples = AllDataExamples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86659c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b0bc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13811f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10  # debug\n",
    "for i_episode in range(num_episodes):\n",
    "    # get one random example\n",
    "    example_id = np.random.randint(0, len(all_data_examples.data))\n",
    "    data_example = all_data_examples.data[example_id]\n",
    "    \n",
    "    # init\n",
    "    bb_id_inc = []\n",
    "    inc_bbs_arr = np.zeros((len(data_example.seq), len(data_example.seq)))\n",
    "    valid_bb_ids = list(data_example.bbs.keys())\n",
    "    current_neg_fe = 0  # inital neg fe 0\n",
    "    \n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        idx_action = select_action(data_example.seq_arr,\n",
    "                               inc_bbs_arr, [data_example.bb_arrs[bb_id] for bb_id in valid_bb_ids])\n",
    "        next_bb_id = valid_bb_ids[idx_action]\n",
    "        \n",
    "        # backup current state before update, so we can store in memory\n",
    "        old_bb_id_inc = bb_id_inc\n",
    "        old_inc_bbs_arr = inc_bbs_arr\n",
    "        old_valid_bb_ids = valid_bb_ids\n",
    "        \n",
    "        # update\n",
    "        valid_bb_ids = find_valid_bb_ids(bb_id_inc, \n",
    "                                 next_bb_id, \n",
    "                                 valid_bb_ids, \n",
    "                                 data_example.bb_conflict)\n",
    "        bb_id_inc.append(next_bb_id)\n",
    "        inc_bbs_arr += data_example.bb_arrs[next_bb_id]\n",
    "\n",
    "        # fe & reward\n",
    "        bp_arr = stem_bbs2arr([data_example.bbs[bb_id] for bb_id in bb_id_inc], len(data_example.seq))\n",
    "        db_str, result_ambiguous = arr2db(bp_arr)  # TODO check \n",
    "        new_neg_fe = - compute_fe(data_example.seq, db_str)\n",
    "        reward = new_neg_fe - current_neg_fe\n",
    "        \n",
    "        # update current fe\n",
    "        current_neg_fe = new_neg_fe + 0  # TODO copy?\n",
    "        \n",
    "        # Store the transition in memory\n",
    "        memory.push(example_id,\n",
    "                    old_bb_id_inc, \n",
    "                    old_inc_bbs_arr, \n",
    "                    old_valid_bb_ids, \n",
    "                    next_bb_id,\n",
    "                    reward)\n",
    "        \n",
    "#         _, reward, done, _ = env.step(action.item())\n",
    "#         reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        \n",
    "        # check if we're at final state\n",
    "        if len(valid_bb_ids) == 0:\n",
    "            break\n",
    "        \n",
    "#         if done:\n",
    "#             episode_durations.append(t + 1)\n",
    "#             plot_durations()\n",
    "#             break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811322ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b804c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_neg_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcc57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neg_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa9e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
