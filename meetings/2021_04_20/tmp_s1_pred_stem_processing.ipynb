{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.rna_ss_utils import one_idx2arr, sort_pairs, LocalStructureParser, make_target_pixel_bb\n",
    "from utils.inference_s1 import Predictor, Evaluator\n",
    "from utils.util_global_struct import process_bb_old_to_new, filter_out_of_range_bb, filter_non_standard_stem, filter_diagonal_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.inference_s1 import DataEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dgutils.pandas as dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_n_proposal(df_bb, threshold):\n",
    "    \n",
    "    if len(df_bb) == 0:\n",
    "        return df_bb\n",
    "    else:\n",
    "        # handle cases where there's only softmax predicted or scalar predicted\n",
    "        if 'prob_other_sm' not in df_bb.columns:\n",
    "            df_bb = dgp.add_column(df_bb, 'prob_sm', ['siz_x'], lambda a: [])  # hacky way to create a column of empty lists\n",
    "        if 'prob_other_sl' not in df_bb.columns:\n",
    "            df_bb = dgp.add_column(df_bb, 'prob_sl', ['siz_x'],\n",
    "                                   lambda a: [])  # hacky way to create a column of empty lists\n",
    "        df_bb = dgp.add_column(df_bb, 'n_proposal_norm_sm', ['prob_other_sm', 'siz_x', 'siz_y'],\n",
    "                          lambda a, b, c: len(a)/float(b * c))\n",
    "        df_bb = dgp.add_column(df_bb, 'n_proposal_norm_sl', ['prob_other_sl', 'siz_x', 'siz_y'],\n",
    "                          lambda a, b, c: len(a)/float(b * c))\n",
    "        return df_bb[(df_bb['n_proposal_norm_sm'] > threshold) | (df_bb['n_proposal_norm_sl'] > threshold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_threshold_on_n_proposal(seq, predictor, threshold):\n",
    "    stems, iloops, hloops = predictor.predict_bb(seq, threshold=0, topk=1, perc_cutoff=0)\n",
    "    stems = pd.DataFrame(stems)\n",
    "#     iloops = pd.DataFrame(iloops)\n",
    "#     hloops = pd.DataFrame(hloops)\n",
    "\n",
    "    stems = filter_by_n_proposal(stems, threshold)\n",
    "#     iloops = filter_by_n_proposal(iloops, threshold)\n",
    "#     hloops = filter_by_n_proposal(hloops, threshold / 2)  # /2 threshold due to /2 upper bound\n",
    "#     return stems, iloops, hloops\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stem_sensitivity_exact(df_target, df_stem):\n",
    "    n_found = 0\n",
    "    \n",
    "    df_target = df_target[df_target['bb_type'] == 'stem']\n",
    "    \n",
    "    for _, target_bb in df_target.iterrows():\n",
    "        bb_x = target_bb['bb_x']\n",
    "        bb_y = target_bb['bb_y']\n",
    "        siz_x = target_bb['siz_x']\n",
    "        siz_y = target_bb['siz_y']\n",
    "       \n",
    "        # try to find bb\n",
    "        df_hit = df_stem[(df_stem['bb_x'] == bb_x) & (df_stem['bb_y'] == bb_y) & (df_stem['siz_x'] == siz_x) & (\n",
    "                df_stem['siz_y'] == siz_y)]\n",
    "        if len(df_hit) == 1:\n",
    "            n_found += 1\n",
    "        elif len(df_hit) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError\n",
    "    return n_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_boundary(bb_x, bb_y, siz_x, siz_y):\n",
    "    x_s = bb_x\n",
    "    y_e = bb_y + 1\n",
    "    x_e = x_s + siz_x\n",
    "    y_s = y_e - siz_y\n",
    "    return x_s, x_e, y_s, y_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stem_sensitivity_within(df_target, df_stem):\n",
    "    \n",
    "    n_found = 0\n",
    "    \n",
    "    df_target = df_target[df_target['bb_type'] == 'stem']\n",
    "    \n",
    "    for _, target_bb in df_target.iterrows():\n",
    "        x_s, x_e, y_s, y_e = bb_boundary(target_bb['bb_x'], target_bb['bb_y'],\n",
    "                                        target_bb['siz_x'], target_bb['siz_y'])\n",
    "        \n",
    "       \n",
    "        # add bb boundary, for easy compariso\n",
    "        df_stem = dgp.add_columns(df_stem, ['x_s', 'x_e', 'y_s', 'y_e'],\n",
    "                                 ['bb_x', 'bb_y', 'siz_x', 'siz_y'], bb_boundary)\n",
    "        \n",
    "        # try to find predicted bb that contains the target bb\n",
    "        # note that it's not sufficient to have the bb1 contain bb2\n",
    "        # their off-diagonal has to overlap\n",
    "        df_hit = df_stem[(df_stem['x_s'] <= x_s) & (\n",
    "            df_stem['x_e'] >= x_e) & (df_stem['y_s'] <= y_s) & (\n",
    "            df_stem['y_e'] >= y_e) & (df_stem['x_e'] - x_e == y_s - df_stem['y_s'])]\n",
    "    \n",
    "        if len(df_hit) > 0:\n",
    "            n_found += 1\n",
    "\n",
    "    return n_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_bb_to_bp(bb_x, bb_y, siz_x, siz_y):\n",
    "    # convert stem bb to base pair indices\n",
    "    # follow convention that base pair (i, j) has i < j\n",
    "    # to make life easier when looking for unique bps when merging multiple bbs\n",
    "    bps = []\n",
    "    x_s, x_e, y_s, y_e = bb_boundary(bb_x, bb_y, siz_x, siz_y)\n",
    "    for ix, iy in zip(range(x_s, x_e), range(y_s, y_e)[::-1]):\n",
    "        assert ix < iy\n",
    "        bps.append((ix, iy))\n",
    "    return bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-engineering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('../2021_03_16/data/human_transcriptome_segment_high_mfe_freq_testing_len64_100.pkl.gz')\n",
    "\n",
    "df = pd.read_pickle('../2021_03_23/data/debug_training_len20_200_100.pkl.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../2021_03_23/s1_training/result/run_7/model_ckpt_ep_17.pth'  # best model\n",
    "\n",
    "predictor = Predictor(model_ckpt=model_path,\n",
    "                     num_filters=[32, 32, 64, 64, 64, 128, 128],\n",
    "                     filter_width=[9, 9, 9, 9, 9, 9, 9],\n",
    "                     dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-shadow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bps = []\n",
    "for idx, row in df.iterrows():\n",
    "#     print(idx)\n",
    "    seq = row['seq']\n",
    "    one_idx = row['one_idx']\n",
    "    bounding_boxes = row['bounding_boxes']\n",
    "    df_target = process_bb_old_to_new(bounding_boxes)\n",
    "    \n",
    "    # threshold on p_on\n",
    "    pred_bb_stem, pred_bb_iloop, pred_bb_hloop = predictor.predict_bb(seq=seq, threshold=0.1, topk=1, perc_cutoff=0)\n",
    "    pred_bb_stem = pd.DataFrame(pred_bb_stem)\n",
    "\n",
    "    # threshold on n_proposal\n",
    "#     pred_bb_stem_2, pred_bb_iloop_2, pred_bb_hloop_2 = pred_threshold_on_n_proposal(seq, predictor, threshold=0.5)\n",
    "    pred_bb_stem_2 = pred_threshold_on_n_proposal(seq, predictor, threshold=0.5)\n",
    "\n",
    "    # combined\n",
    "    df_stem = pd.concat([pred_bb_stem, pred_bb_stem_2]).drop_duplicates(subset=['bb_x', 'bb_y', 'siz_x', 'siz_y'])\n",
    "    \n",
    "    # pruning\n",
    "    # remove out-of-bound bb\n",
    "    df_stem = filter_out_of_range_bb(df_stem, len(row['seq']))\n",
    "    # stem - non standard base pairing\n",
    "    df_stem = filter_non_standard_stem(df_stem, row['seq'])\n",
    "    # for stem, we need the bb bottom left corner to be in the upper triangular (exclude diagonal), i.e. i < j\n",
    "    df_stem = filter_diagonal_stem(df_stem)\n",
    "    \n",
    "    # check stem sensitivity\n",
    "    print(\"Idx {}, n_target_stem {}, n_exact_hit {}, n_within_hit {}\".format(idx, len(df_target[df_target['bb_type'] == 'stem']),\n",
    "                                                                            check_stem_sensitivity_exact(df_target, df_stem),\n",
    "                                                                            check_stem_sensitivity_within(df_target, df_stem)))\n",
    "    \n",
    "    \n",
    "    # for now only use examples with 100% sensitivy (for target equal/within pred bb)\n",
    "    if len(df_target[df_target['bb_type'] == 'stem']) > check_stem_sensitivity_within(df_target, df_stem):\n",
    "        print(\"Skip example for now.\")\n",
    "        continue\n",
    "    \n",
    "    assert len(df_target[df_target['bb_type'] == 'stem']) == check_stem_sensitivity_within(df_target, df_stem)\n",
    "    \n",
    "    # extract base pair indices\n",
    "    # pred\n",
    "    stem_bb_bps = []\n",
    "    for _, r in df_stem.iterrows():\n",
    "        bps = stem_bb_to_bp(r['bb_x'], r['bb_y'], r['siz_x'], r['siz_y'])\n",
    "        stem_bb_bps.extend(bps)\n",
    "    stem_bb_bps = sorted(list(set(stem_bb_bps)))  # remove duplicates (some pred bb might be within other pred bb)\n",
    "    # target\n",
    "    target_bps = []\n",
    "    for _, r in df_target[df_target['bb_type'] == 'stem'].iterrows():\n",
    "        bps = stem_bb_to_bp(r['bb_x'], r['bb_y'], r['siz_x'], r['siz_y'])\n",
    "        target_bps.extend(bps)\n",
    "        \n",
    "    # double check that target_bps is subset of stem_bb_bps\n",
    "    assert set(target_bps).issubset(set(stem_bb_bps))\n",
    "    \n",
    "    # export\n",
    "    row_new = row.copy()\n",
    "    row_new['stem_bb_bps'] = stem_bb_bps\n",
    "    row_new['target_bps'] = target_bps\n",
    "    df_bps.append(row_new)\n",
    "    \n",
    "#     # debug\n",
    "# #     break\n",
    "#     if idx >= 3:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-worthy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-biology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bps = pd.DataFrame(df_bps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bps.to_pickle('data/debug_training_len20_200_100_s1_pred_stem_bps.pkl.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stem_bb_bps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_bps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check graph connection density\n",
    "# n_edge per node distribution\n",
    "\n",
    "n_edge_per_node = defaultdict(lambda: 0)\n",
    "for bp in stem_bb_bps:\n",
    "    n_edge_per_node[bp[0]] += 1\n",
    "    n_edge_per_node[bp[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(n_edge_per_node.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-individual",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
