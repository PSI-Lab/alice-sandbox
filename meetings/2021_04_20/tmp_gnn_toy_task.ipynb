{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(df):\n",
    "    data_list = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        seq = row['seq']\n",
    "        stem_bb_bps = row['stem_bb_bps']\n",
    "#         target_bps = row['target_bps']\n",
    "\n",
    "        # use integer encoding for now\n",
    "        seq_int = seq.upper().replace('A', '1').replace('C', '2').replace('G', '3').replace('T', '4').replace('U', '4').replace('N', '0')\n",
    "        tmp = np.asarray(list(map(int, list(seq_int))), dtype=np.int16)\n",
    "        # one-hot\n",
    "        node_features = np.zeros((len(seq), 4))\n",
    "        node_features[np.arange(len(seq)),tmp-1] = 1\n",
    "        node_features = torch.from_numpy(node_features).float()\n",
    "#         node_features = torch.LongTensor(node_features).unsqueeze(1)  # FIXME dtype\n",
    "\n",
    "        # build edges\n",
    "        edge_from = []\n",
    "        edge_to = []\n",
    "        # chain - undirected edge for now\n",
    "        node_left = range(0, len(seq) - 1)\n",
    "        node_right = range(1, len(seq))\n",
    "        edge_from.extend(node_left)\n",
    "        edge_to.extend(node_right)\n",
    "        edge_from.extend(node_right)\n",
    "        edge_to.extend(node_left)\n",
    "        assert len(edge_from) == len(edge_to)\n",
    "        n_edge_1 = len(edge_from)  # number of 'backbone' edges\n",
    "        # pair matrix - undirected edge \n",
    "        # for all predicted stem bbs\n",
    "        for idx_left, idx_right in stem_bb_bps:\n",
    "            edge_from.append(idx_left)\n",
    "            edge_to.append(idx_right)\n",
    "            edge_from.append(idx_right)\n",
    "            edge_to.append(idx_left)\n",
    "        assert len(edge_from) == len(edge_to)\n",
    "        n_edge_2 = len(edge_from) - n_edge_1  # number of 'hydrogen bond' edges\n",
    "        edge_index = torch.tensor([edge_from, edge_to], dtype=torch.long)\n",
    "\n",
    "        # edge feature, 0 for \"backbone\", 1 for \"hydrogen bond\", later on we will encode it\n",
    "        edge_attr = torch.LongTensor([0] * n_edge_1 + [1] * n_edge_2).unsqueeze(1)  # FIXME dtype\n",
    "\n",
    "        # target: edge label\n",
    "        # binary matrix of size lxl\n",
    "        # toy task: label all G-C in stem_bb_bps as 1 and others as 0\n",
    "        target_bps = []\n",
    "        for i, j in stem_bb_bps:\n",
    "            if seq[i] == 'G' and seq[j] == 'C' or seq[i] == 'C' and seq[j] == 'G':\n",
    "                target_bps.append((i, j))\n",
    "        \n",
    "        y = np.zeros((len(seq), len(seq)))\n",
    "        y[tuple(zip(*target_bps))] = 1\n",
    "        # mask: locations with 0 are don't-cares\n",
    "        # these are pred stem bb bps\n",
    "        m = np.zeros((len(seq), len(seq)))\n",
    "        m[tuple(zip(*stem_bb_bps))] = 1\n",
    "        \n",
    "#         # make data point\n",
    "#         # store both target and mask in y\n",
    "#         data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr,\n",
    "#                    y={'target': y, 'mask': m})\n",
    "        # make data point\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                   y=y, m=m)\n",
    "        \n",
    "        data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_hid=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch_geometric.nn.conv.GATConv(4, n_hid)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.Sigmoid()\n",
    "    \n",
    "        # node-node NN\n",
    "        self.node_pair_conv1 = torch.nn.Conv2d(n_hid*2, n_hid, kernel_size=1, stride=1,\n",
    "                                            padding=0)\n",
    "        self.node_pair_conv2 = torch.nn.Conv2d(n_hid, 1, kernel_size=1, stride=1,\n",
    "                                            padding=0)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.act1(self.conv1(data.x, data.edge_index))\n",
    "        \n",
    "        # outer concat: L x L x 2f\n",
    "        x1 = x.unsqueeze(1).repeat(1, x.size(0), 1)\n",
    "        x2 = x.unsqueeze(0).repeat(x.size(0), 1, 1)\n",
    "        x = torch.cat([x1, x2], axis=2)\n",
    "        \n",
    "        # FC along last dim\n",
    "        # note that conv_2d expects Input: (N, C_{in}, H_{in}, W_{in})\n",
    "        x = x.permute(2, 0, 1).unsqueeze(0)\n",
    "        x = self.act1(self.node_pair_conv1(x))\n",
    "        x = self.act2(self.node_pair_conv2(x))\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_b = torch.nn.BCELoss(reduction='none')\n",
    "\n",
    "\n",
    "def debug_loss(x, y, m):\n",
    "    # L x L\n",
    "    l = loss_b(x, y)\n",
    "    return torch.mean(l)\n",
    "\n",
    "\n",
    "def masked_loss_b(x, y, m):\n",
    "    # L x L\n",
    "#     x = x.squeeze()  # L x L\n",
    "#     y = y.squeeze()  # L x L\n",
    "    l = loss_b(x, y)\n",
    "    n_valid_output = torch.sum(m)\n",
    "    loss_spatial_sum = torch.sum(torch.mul(l, m))\n",
    "    loss_spatial_mean = loss_spatial_sum / n_valid_output\n",
    "    loss_batch_mean = torch.mean(loss_spatial_mean, dim=0)\n",
    "    return torch.mean(loss_batch_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_prc(x, y, m):\n",
    "    # true, score, mask\n",
    "    mask_bool = m.eq(1)\n",
    "    _x2 = x.masked_select(mask_bool).flatten().detach().cpu().numpy()\n",
    "    _y2 = y.masked_select(mask_bool).flatten().detach().cpu().numpy()\n",
    "    # do not compute if empty (e.g. when all elements are being masked)\n",
    "    # do not compute if there's only one class\n",
    "    if len(_x2) > 0 and not np.all(_x2 == _x2[0]):\n",
    "        roc = roc_auc_score(_x2, _y2)\n",
    "        prc = average_precision_score(_x2, _y2)\n",
    "    else:\n",
    "        roc = np.NaN\n",
    "        prc = np.NaN\n",
    "    return roc, prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/debug_training_len20_200_100_s1_pred_stem_bps.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = DataLoader(make_dataset(df), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = make_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(n_hid=10)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    random.shuffle(data_list)\n",
    "    \n",
    "    loss_all = []\n",
    "    auc_all = []\n",
    "    \n",
    "    for data in data_list:\n",
    "        y = torch.from_numpy(data.y).float()\n",
    "        m = torch.from_numpy(data.m).float()\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = masked_loss_b(pred, y, m)\n",
    "        loss_all.append(loss.item())\n",
    "        auc, prc = roc_prc(y, pred, m)\n",
    "        auc_all.append(auc)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch {}, mean loss {}, mean AUC {}\".format(epoch, np.mean(loss_all), np.mean(auc_all)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(pred.detach().numpy() * m.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
