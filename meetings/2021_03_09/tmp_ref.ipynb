{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "average-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elect-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crude-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enormous-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=20\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-conservation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CVAE(nn.Module):\n",
    "#     def __init__(self, x_dim, h_dim, z_dim, y_dim):\n",
    "#         super(CVAE, self).__init__()\n",
    "        \n",
    "#         # encoder part\n",
    "#         self.fc1 = nn.Linear(x_dim + y_dim, h_dim)\n",
    "#         self.fc21 = nn.Linear(h_dim, z_dim)\n",
    "#         self.fc22 = nn.Linear(h_dim, z_dim)\n",
    "#         # decoder part\n",
    "#         self.fc3 = nn.Linear(z_dim + x_dim, h_dim)\n",
    "#         self.fc4 = nn.Linear(h_dim, y_dim)\n",
    "    \n",
    "#     def encoder(self, x, y):\n",
    "#         concat_input = torch.cat([x, y], 1)\n",
    "#         h = F.relu(self.fc1(concat_input))\n",
    "#         return self.fc21(h), self.fc22(h)\n",
    "    \n",
    "#     def sampling(self, mu, log_var):\n",
    "#         std = torch.exp(0.5*log_var)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return eps.mul(std).add(mu) # return z sample\n",
    "    \n",
    "#     def decoder(self, z, x):\n",
    "#         concat_input = torch.cat([z, x.view(-1, 784)], 1)\n",
    "#         h = F.relu(self.fc3(concat_input))\n",
    "#         return F.log_softmax(self.fc4(h))\n",
    "    \n",
    "#     def forward(self, x, y):\n",
    "#         mu, log_var = self.encoder(x.view(-1, 784), y)\n",
    "#         z = self.sampling(mu, log_var)\n",
    "#         return self.decoder(z, x), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "empirical-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # condition after convolution\n",
    "\n",
    "# class CVAE(nn.Module):\n",
    "#     def __init__(self, x_dim, h1_dim, h2_dim, z_dim, y_dim):\n",
    "#         super(CVAE, self).__init__()\n",
    "        \n",
    "#         # encoder part\n",
    "#         self.fc1 = nn.Linear(x_dim, h1_dim)\n",
    "#         self.fc2 = nn.Linear(h1_dim + y_dim, h2_dim)\n",
    "#         self.fc31 = nn.Linear(h2_dim, z_dim)\n",
    "#         self.fc32 = nn.Linear(h2_dim, z_dim)\n",
    "#         # decoder part\n",
    "#         self.fc4 = nn.Linear(x_dim, h1_dim)\n",
    "#         self.fc5 = nn.Linear(h1_dim + y_dim, h2_dim)\n",
    "#         self.fc6 = nn.Linear(h2_dim, y_dim)\n",
    "    \n",
    "#     def encoder(self, x, y):\n",
    "# #         concat_input = torch.cat([x, y], 1)\n",
    "#         h1 = F.relu(self.fc1(x))\n",
    "#         h2 = F.relu(self.fc2(torch.cat([h1, y], 1)))\n",
    "#         return self.fc31(h2), self.fc32(h2)\n",
    "    \n",
    "#     def sampling(self, mu, log_var):\n",
    "#         std = torch.exp(0.5*log_var)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return eps.mul(std).add(mu) # return z sample\n",
    "    \n",
    "#     def decoder(self, z, x):\n",
    "#         h1 = F.relu(self.fc4(x.view(-1, 784)))\n",
    "#         h2 = F.relu(self.fc5(torch.cat([h1, z], 1)))\n",
    "#         return F.log_softmax(self.fc6(h2))\n",
    "    \n",
    "#     def forward(self, x, y):\n",
    "#         mu, log_var = self.encoder(x.view(-1, 784), y)\n",
    "#         z = self.sampling(mu, log_var)\n",
    "#         return self.decoder(z, x), mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dated-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition after convolution\n",
    "# more hidden layers\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, x_dim, hs_dim, z_dim, y_dim, tie_weights=False):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        assert len(hs_dim) >= 2\n",
    "        self.tie_weights = tie_weights\n",
    "        \n",
    "        # encoder part for x\n",
    "        self.encode_x = []\n",
    "        for i, h_dim in enumerate(hs_dim[:-1]):\n",
    "            if i == 0:\n",
    "                self.encode_x.append(nn.Linear(x_dim, h_dim))\n",
    "            else:\n",
    "                self.encode_x.append(nn.Linear(hs_dim[i-1], h_dim))\n",
    "        # last layer of encoder combines x and y\n",
    "        self.encode_xy = nn.Linear(hs_dim[-2] + y_dim, hs_dim[-1])\n",
    "        # compute posterior distribution parameters\n",
    "        self.posterior_mean = nn.Linear(hs_dim[-1], z_dim)\n",
    "        self.posterior_logvar = nn.Linear(hs_dim[-1], z_dim)\n",
    "        \n",
    "        # prior network\n",
    "        if not self.tie_weights:\n",
    "            self.prior_x = []\n",
    "            for i, h_dim in enumerate(hs_dim[:-1]):\n",
    "                if i == 0:\n",
    "                    self.prior_x.append(nn.Linear(x_dim, h_dim))\n",
    "                else:\n",
    "                    self.prior_x.append(nn.Linear(hs_dim[i-1], h_dim))\n",
    "        else:\n",
    "            self.prior_x = self.encode_x\n",
    "        self.prior_mean = nn.Linear(hs_dim[-2], z_dim)\n",
    "        self.prior_logvar = nn.Linear(hs_dim[-2], z_dim)\n",
    "        \n",
    "        if not self.tie_weights:\n",
    "            # decoder part for x\n",
    "            self.decode_x = []\n",
    "            for i, h_dim in enumerate(hs_dim[:-1]):\n",
    "                if i == 0:\n",
    "                    self.decode_x.append(nn.Linear(x_dim, h_dim))\n",
    "                else:\n",
    "                    self.decode_x.append(nn.Linear(hs_dim[i-1], h_dim))\n",
    "        else:\n",
    "            self.decode_x = self.encode_x\n",
    "        # last layer of decoder combines x and z\n",
    "        self.decode_xz = nn.Linear(hs_dim[-2] + z_dim, hs_dim[-1])\n",
    "        # compute y\n",
    "        self.output = nn.Linear(hs_dim[-1], y_dim)\n",
    "    \n",
    "    def prior(self, x):\n",
    "        for layer in self.prior_x:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.prior_mean(x), self.prior_logvar(x)\n",
    "    \n",
    "    def encoder(self, x, y):\n",
    "        for layer in self.encode_x:\n",
    "            x = F.relu(layer(x))\n",
    "        h = F.relu(self.encode_xy(torch.cat([x, y], 1)))\n",
    "        return self.posterior_mean(h), self.posterior_logvar(h)\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add(mu) # return z sample\n",
    "    \n",
    "    def decoder(self, z, x):\n",
    "        for layer in self.decode_x:\n",
    "            x = F.relu(layer(x))\n",
    "        h = F.relu(self.decode_xz(torch.cat([x, z], 1)))\n",
    "        return F.log_softmax(self.output(h))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = x.view(-1, 784)\n",
    "        mu_q, log_var_q = self.encoder(x, y)\n",
    "        mu_p, log_var_p = self.prior(x)\n",
    "        z = self.sampling(mu_q, log_var_q)\n",
    "        return self.decoder(z, x), mu_q, log_var_q, mu_p, log_var_p\n",
    "    \n",
    "    def inference(self, x):\n",
    "        # not efficient for multiple samples since the common part to encode x will be run multiple times!\n",
    "        x = x.view(-1, 784)\n",
    "        mu_p, log_var_p = self.prior(x)\n",
    "        z = self.sampling(mu_p, log_var_p )\n",
    "        return self.decoder(z, x), mu_p, log_var_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pressing-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# z_dim = 10\n",
    "z_dim = 2\n",
    "\n",
    "# cvae = CVAE(x_dim=784, h1_dim=50, h2_dim=10, z_dim=z_dim, y_dim=10)\n",
    "\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[20, 10, 10], z_dim=z_dim, y_dim=10)\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[20, 10, 5], z_dim=z_dim, y_dim=10)\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[50, 10, 5], z_dim=z_dim, y_dim=10)\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[50, 10, 10], z_dim=z_dim, y_dim=10)\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[50, 10], z_dim=z_dim, y_dim=10)\n",
    "# cvae = CVAE(x_dim=784, hs_dim=[50, 10, 5, 10], z_dim=z_dim, y_dim=10)\n",
    "\n",
    "cvae = CVAE(x_dim=784, hs_dim=[20, 10, 10], z_dim=z_dim, y_dim=10, tie_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-housing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "considerable-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE(\n",
       "  (encode_xy): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (posterior_mean): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (posterior_logvar): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (prior_mean): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (prior_logvar): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (decode_xz): Linear(in_features=12, out_features=10, bias=True)\n",
       "  (output): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-deviation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "documentary-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cvae.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "gross-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax_loss = nn.NLLLoss(reduction='sum')  \n",
    "\n",
    "# # return reconstruction error + KL divergence losses\n",
    "# def loss_function(y_pred, y, mu, log_var):\n",
    "#     sm_loss = log_softmax_loss(y_pred, y)\n",
    "#     KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "#     return sm_loss, KLD\n",
    "\n",
    "def loss_function(y_pred, y, mu_q, log_var_q, mu_p, log_var_p):\n",
    "    sm_loss = log_softmax_loss(y_pred, y)\n",
    "    KLD = 0.5 * torch.sum(log_var_q.exp()/log_var_p.exp() + \\\n",
    "                          (mu_p - mu_q).pow(2)/log_var_p.exp() - 1 + \\\n",
    "                          log_var_p - log_var_q)\n",
    "    return sm_loss, KLD\n",
    "\n",
    "# one-hot encoding\n",
    "def one_hot(labels, class_size): \n",
    "    targets = torch.zeros(labels.size(0), class_size)\n",
    "    for i, label in enumerate(labels):\n",
    "        targets[i, label] = 1\n",
    "    return Variable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "little-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    cvae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = torch.cat([x_batch, x_batch], 0)\n",
    "        \n",
    "        # make toy data\n",
    "        y_batch_p1 = y_batch + 1\n",
    "        y_batch_p1[y_batch_p1==10] = 0\n",
    "        y_batch = torch.cat([y_batch, y_batch_p1], 0)\n",
    "\n",
    "        y_oh_batch = one_hot(y_batch, class_size=10)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred, mu_q, log_var_q, mu_p, log_var_p = cvae(x_batch, y_oh_batch)\n",
    "        sm_loss, KLD = loss_function(y_pred, y_batch, mu_q, log_var_q, mu_p, log_var_p)\n",
    "        loss = sm_loss + KLD\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} = {:.6f} + {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x_batch), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(),\n",
    "            sm_loss.item(), KLD.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "blocked-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    cvae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            y_oh_batch = one_hot(y_batch, class_size=10)\n",
    "            y_pred, mu_q, log_var_q, mu_p, log_var_p = cvae(x_batch, y_oh_batch)\n",
    "            # sum up batch loss\n",
    "            sm_loss, KLD = loss_function(y_pred, y_batch, mu_q, log_var_q, mu_p, log_var_p)\n",
    "            test_loss += (sm_loss.item() + KLD.item())\n",
    "        \n",
    "    test_loss /= (len(test_loader.dataset)/test_loader.batch_size)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-crazy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outer-battle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 94.002426 = 92.867424 + 1.135002\n",
      "Train Epoch: 0 [4000/60000 (3%)]\tLoss: 91.394218 = 91.320541 + 0.073676\n",
      "Train Epoch: 0 [8000/60000 (7%)]\tLoss: 92.241623 = 92.183289 + 0.058338\n",
      "Train Epoch: 0 [12000/60000 (10%)]\tLoss: 92.224869 = 92.157936 + 0.066933\n",
      "Train Epoch: 0 [16000/60000 (13%)]\tLoss: 91.377235 = 91.308296 + 0.068942\n",
      "Train Epoch: 0 [20000/60000 (17%)]\tLoss: 93.038116 = 92.976807 + 0.061309\n",
      "Train Epoch: 0 [24000/60000 (20%)]\tLoss: 92.349525 = 92.255096 + 0.094428\n",
      "Train Epoch: 0 [28000/60000 (23%)]\tLoss: 91.850868 = 91.782982 + 0.067885\n",
      "Train Epoch: 0 [32000/60000 (27%)]\tLoss: 92.420036 = 92.321617 + 0.098419\n",
      "Train Epoch: 0 [36000/60000 (30%)]\tLoss: 91.731323 = 91.632942 + 0.098385\n",
      "Train Epoch: 0 [40000/60000 (33%)]\tLoss: 91.868729 = 91.773781 + 0.094947\n",
      "Train Epoch: 0 [44000/60000 (37%)]\tLoss: 91.580704 = 91.490250 + 0.090455\n",
      "Train Epoch: 0 [48000/60000 (40%)]\tLoss: 91.187706 = 91.098366 + 0.089339\n",
      "Train Epoch: 0 [52000/60000 (43%)]\tLoss: 91.802887 = 91.706390 + 0.096500\n",
      "Train Epoch: 0 [56000/60000 (47%)]\tLoss: 91.395226 = 91.285919 + 0.109305\n",
      "Train Epoch: 0 [60000/60000 (50%)]\tLoss: 90.072762 = 89.943268 + 0.129492\n",
      "Train Epoch: 0 [64000/60000 (53%)]\tLoss: 91.897491 = 91.798676 + 0.098812\n",
      "Train Epoch: 0 [68000/60000 (57%)]\tLoss: 91.323463 = 91.191895 + 0.131566\n",
      "Train Epoch: 0 [72000/60000 (60%)]\tLoss: 90.313293 = 90.181740 + 0.131556\n",
      "Train Epoch: 0 [76000/60000 (63%)]\tLoss: 92.840637 = 92.707497 + 0.133140\n",
      "Train Epoch: 0 [80000/60000 (67%)]\tLoss: 89.908554 = 89.749603 + 0.158949\n",
      "Train Epoch: 0 [84000/60000 (70%)]\tLoss: 91.113480 = 90.910446 + 0.203032\n",
      "Train Epoch: 0 [88000/60000 (73%)]\tLoss: 88.834816 = 88.674049 + 0.160769\n",
      "Train Epoch: 0 [92000/60000 (77%)]\tLoss: 89.580658 = 89.413895 + 0.166763\n",
      "Train Epoch: 0 [96000/60000 (80%)]\tLoss: 91.203583 = 91.002617 + 0.200965\n",
      "Train Epoch: 0 [100000/60000 (83%)]\tLoss: 91.564758 = 91.355392 + 0.209368\n",
      "Train Epoch: 0 [104000/60000 (87%)]\tLoss: 87.042572 = 86.893021 + 0.149555\n",
      "Train Epoch: 0 [108000/60000 (90%)]\tLoss: 86.776443 = 86.560791 + 0.215653\n",
      "Train Epoch: 0 [112000/60000 (93%)]\tLoss: 86.071831 = 85.900871 + 0.170962\n",
      "Train Epoch: 0 [116000/60000 (97%)]\tLoss: 92.487206 = 92.331161 + 0.156044\n",
      "====> Test set loss: 44.0118\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 92.629837 = 92.457123 + 0.172716\n",
      "Train Epoch: 1 [4000/60000 (3%)]\tLoss: 90.680618 = 90.460175 + 0.220444\n",
      "Train Epoch: 1 [8000/60000 (7%)]\tLoss: 84.349136 = 84.175125 + 0.174011\n",
      "Train Epoch: 1 [12000/60000 (10%)]\tLoss: 88.221519 = 87.975533 + 0.245990\n",
      "Train Epoch: 1 [16000/60000 (13%)]\tLoss: 85.132912 = 84.785683 + 0.347225\n",
      "Train Epoch: 1 [20000/60000 (17%)]\tLoss: 87.076172 = 86.825226 + 0.250944\n",
      "Train Epoch: 1 [24000/60000 (20%)]\tLoss: 86.896759 = 86.635277 + 0.261479\n",
      "Train Epoch: 1 [28000/60000 (23%)]\tLoss: 88.156303 = 87.863937 + 0.292364\n",
      "Train Epoch: 1 [32000/60000 (27%)]\tLoss: 87.152351 = 86.906914 + 0.245437\n",
      "Train Epoch: 1 [36000/60000 (30%)]\tLoss: 88.308914 = 87.958618 + 0.350295\n",
      "Train Epoch: 1 [40000/60000 (33%)]\tLoss: 89.695732 = 89.374825 + 0.320906\n",
      "Train Epoch: 1 [44000/60000 (37%)]\tLoss: 88.899956 = 88.559166 + 0.340792\n",
      "Train Epoch: 1 [48000/60000 (40%)]\tLoss: 85.044029 = 84.717293 + 0.326739\n",
      "Train Epoch: 1 [52000/60000 (43%)]\tLoss: 87.598778 = 87.203011 + 0.395768\n",
      "Train Epoch: 1 [56000/60000 (47%)]\tLoss: 89.945717 = 89.579033 + 0.366686\n",
      "Train Epoch: 1 [60000/60000 (50%)]\tLoss: 89.068336 = 88.720573 + 0.347766\n",
      "Train Epoch: 1 [64000/60000 (53%)]\tLoss: 87.582771 = 87.285919 + 0.296853\n",
      "Train Epoch: 1 [68000/60000 (57%)]\tLoss: 89.249283 = 88.735497 + 0.513786\n",
      "Train Epoch: 1 [72000/60000 (60%)]\tLoss: 86.105766 = 85.399879 + 0.705883\n",
      "Train Epoch: 1 [76000/60000 (63%)]\tLoss: 84.479919 = 83.805588 + 0.674330\n",
      "Train Epoch: 1 [80000/60000 (67%)]\tLoss: 87.865013 = 87.181335 + 0.683676\n",
      "Train Epoch: 1 [84000/60000 (70%)]\tLoss: 88.115448 = 87.453690 + 0.661757\n",
      "Train Epoch: 1 [88000/60000 (73%)]\tLoss: 81.474373 = 80.914001 + 0.560374\n",
      "Train Epoch: 1 [92000/60000 (77%)]\tLoss: 89.000237 = 88.171791 + 0.828449\n",
      "Train Epoch: 1 [96000/60000 (80%)]\tLoss: 81.765724 = 81.039627 + 0.726100\n",
      "Train Epoch: 1 [100000/60000 (83%)]\tLoss: 82.251564 = 81.536270 + 0.715293\n",
      "Train Epoch: 1 [104000/60000 (87%)]\tLoss: 83.587303 = 82.901985 + 0.685316\n",
      "Train Epoch: 1 [108000/60000 (90%)]\tLoss: 80.638527 = 79.925659 + 0.712869\n",
      "Train Epoch: 1 [112000/60000 (93%)]\tLoss: 82.639328 = 81.979370 + 0.659954\n",
      "Train Epoch: 1 [116000/60000 (97%)]\tLoss: 81.162560 = 80.321892 + 0.840668\n",
      "====> Test set loss: 42.6718\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 86.165848 = 85.482162 + 0.683687\n",
      "Train Epoch: 2 [4000/60000 (3%)]\tLoss: 81.076958 = 80.325516 + 0.751445\n",
      "Train Epoch: 2 [8000/60000 (7%)]\tLoss: 91.443672 = 90.617081 + 0.826588\n",
      "Train Epoch: 2 [12000/60000 (10%)]\tLoss: 77.806847 = 76.886086 + 0.920759\n",
      "Train Epoch: 2 [16000/60000 (13%)]\tLoss: 83.831253 = 82.934883 + 0.896370\n",
      "Train Epoch: 2 [20000/60000 (17%)]\tLoss: 85.332436 = 84.695404 + 0.637033\n",
      "Train Epoch: 2 [24000/60000 (20%)]\tLoss: 85.008698 = 84.102280 + 0.906414\n",
      "Train Epoch: 2 [28000/60000 (23%)]\tLoss: 84.088257 = 83.343872 + 0.744388\n",
      "Train Epoch: 2 [32000/60000 (27%)]\tLoss: 83.319290 = 82.572311 + 0.746975\n",
      "Train Epoch: 2 [36000/60000 (30%)]\tLoss: 85.094864 = 84.375534 + 0.719331\n",
      "Train Epoch: 2 [40000/60000 (33%)]\tLoss: 80.543259 = 79.723946 + 0.819310\n",
      "Train Epoch: 2 [44000/60000 (37%)]\tLoss: 85.108727 = 84.334686 + 0.774040\n",
      "Train Epoch: 2 [48000/60000 (40%)]\tLoss: 83.499908 = 82.764458 + 0.735450\n",
      "Train Epoch: 2 [52000/60000 (43%)]\tLoss: 87.105164 = 86.285156 + 0.820010\n",
      "Train Epoch: 2 [56000/60000 (47%)]\tLoss: 90.720352 = 89.806076 + 0.914276\n",
      "Train Epoch: 2 [60000/60000 (50%)]\tLoss: 80.450920 = 79.684135 + 0.766784\n",
      "Train Epoch: 2 [64000/60000 (53%)]\tLoss: 84.314453 = 83.402077 + 0.912376\n",
      "Train Epoch: 2 [68000/60000 (57%)]\tLoss: 84.897247 = 83.939270 + 0.957977\n",
      "Train Epoch: 2 [72000/60000 (60%)]\tLoss: 84.041992 = 83.029510 + 1.012483\n",
      "Train Epoch: 2 [76000/60000 (63%)]\tLoss: 91.854874 = 91.186028 + 0.668843\n",
      "Train Epoch: 2 [80000/60000 (67%)]\tLoss: 79.521523 = 78.949402 + 0.572122\n",
      "Train Epoch: 2 [84000/60000 (70%)]\tLoss: 82.197853 = 81.610489 + 0.587361\n",
      "Train Epoch: 2 [88000/60000 (73%)]\tLoss: 84.290276 = 83.442383 + 0.847890\n",
      "Train Epoch: 2 [92000/60000 (77%)]\tLoss: 92.431274 = 91.442764 + 0.988514\n",
      "Train Epoch: 2 [96000/60000 (80%)]\tLoss: 80.276596 = 79.439026 + 0.837571\n",
      "Train Epoch: 2 [100000/60000 (83%)]\tLoss: 81.903481 = 80.795250 + 1.108234\n",
      "Train Epoch: 2 [104000/60000 (87%)]\tLoss: 85.029877 = 84.021690 + 1.008187\n",
      "Train Epoch: 2 [108000/60000 (90%)]\tLoss: 88.903732 = 87.993492 + 0.910241\n",
      "Train Epoch: 2 [112000/60000 (93%)]\tLoss: 84.669151 = 83.564468 + 1.104680\n",
      "Train Epoch: 2 [116000/60000 (97%)]\tLoss: 85.000366 = 83.902878 + 1.097492\n",
      "====> Test set loss: 42.0075\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 82.120667 = 81.056084 + 1.064579\n",
      "Train Epoch: 3 [4000/60000 (3%)]\tLoss: 85.558334 = 84.491356 + 1.066982\n",
      "Train Epoch: 3 [8000/60000 (7%)]\tLoss: 84.415977 = 83.576561 + 0.839416\n",
      "Train Epoch: 3 [12000/60000 (10%)]\tLoss: 87.826561 = 86.934166 + 0.892393\n",
      "Train Epoch: 3 [16000/60000 (13%)]\tLoss: 81.892471 = 81.147209 + 0.745264\n",
      "Train Epoch: 3 [20000/60000 (17%)]\tLoss: 89.177376 = 88.095619 + 1.081754\n",
      "Train Epoch: 3 [24000/60000 (20%)]\tLoss: 86.898186 = 85.930504 + 0.967679\n",
      "Train Epoch: 3 [28000/60000 (23%)]\tLoss: 83.172104 = 82.396713 + 0.775390\n",
      "Train Epoch: 3 [32000/60000 (27%)]\tLoss: 84.725693 = 83.794678 + 0.931018\n",
      "Train Epoch: 3 [36000/60000 (30%)]\tLoss: 85.938591 = 85.115158 + 0.823429\n",
      "Train Epoch: 3 [40000/60000 (33%)]\tLoss: 82.748528 = 82.019058 + 0.729473\n",
      "Train Epoch: 3 [44000/60000 (37%)]\tLoss: 96.112793 = 95.254913 + 0.857878\n",
      "Train Epoch: 3 [48000/60000 (40%)]\tLoss: 81.443359 = 80.668839 + 0.774518\n",
      "Train Epoch: 3 [52000/60000 (43%)]\tLoss: 84.302467 = 83.427155 + 0.875315\n",
      "Train Epoch: 3 [56000/60000 (47%)]\tLoss: 83.384239 = 82.563240 + 0.820999\n",
      "Train Epoch: 3 [60000/60000 (50%)]\tLoss: 85.518219 = 84.796982 + 0.721241\n",
      "Train Epoch: 3 [64000/60000 (53%)]\tLoss: 85.796791 = 85.110756 + 0.686036\n",
      "Train Epoch: 3 [68000/60000 (57%)]\tLoss: 79.927399 = 79.203621 + 0.723780\n",
      "Train Epoch: 3 [72000/60000 (60%)]\tLoss: 80.549141 = 79.965965 + 0.583174\n",
      "Train Epoch: 3 [76000/60000 (63%)]\tLoss: 81.485054 = 80.760521 + 0.724531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [80000/60000 (67%)]\tLoss: 82.504440 = 81.686958 + 0.817480\n",
      "Train Epoch: 3 [84000/60000 (70%)]\tLoss: 85.784752 = 84.953217 + 0.831534\n",
      "Train Epoch: 3 [88000/60000 (73%)]\tLoss: 83.300102 = 82.557289 + 0.742814\n",
      "Train Epoch: 3 [92000/60000 (77%)]\tLoss: 80.533394 = 79.711380 + 0.822011\n",
      "Train Epoch: 3 [96000/60000 (80%)]\tLoss: 87.246643 = 86.545555 + 0.701087\n",
      "Train Epoch: 3 [100000/60000 (83%)]\tLoss: 83.874985 = 82.922119 + 0.952869\n",
      "Train Epoch: 3 [104000/60000 (87%)]\tLoss: 84.142288 = 83.206787 + 0.935499\n",
      "Train Epoch: 3 [108000/60000 (90%)]\tLoss: 84.657822 = 83.505867 + 1.151955\n",
      "Train Epoch: 3 [112000/60000 (93%)]\tLoss: 84.446526 = 83.441254 + 1.005269\n",
      "Train Epoch: 3 [116000/60000 (97%)]\tLoss: 84.505043 = 83.498192 + 1.006850\n",
      "====> Test set loss: 41.8416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # TODO more epochs?\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fancy-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random image\n",
    "\n",
    "# num_row = 4\n",
    "# num_col = 5\n",
    "# num = num_row * num_col\n",
    "\n",
    "# fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "# for i in range(num):\n",
    "#     ax = axes[i//num_col, i%num_col]\n",
    "#     idx = random.randint(a=0, b=10000)\n",
    "#     tmp = test_dataset[idx][0]\n",
    "#     ax.imshow(tmp.numpy()[0, :, :], cmap='gray', interpolation='none')\n",
    "#     ax.set_title('i:{} l:{}'.format(idx, test_dataset[idx][1]))\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-explosion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "funny-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction\n",
    "# only running 'decoder', i.e. x, z -> y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "constant-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcbb8ee88d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x_debug, y_debug = train_dataset[500]\n",
    "\n",
    "\n",
    "\n",
    "x_debug, y_debug = test_dataset[5]\n",
    "\n",
    "# x_debug, y_debug = test_dataset[7]\n",
    "\n",
    "# x_debug, y_debug = test_dataset[10]\n",
    "\n",
    "# x_debug, y_debug = test_dataset[500]\n",
    "\n",
    "\n",
    "# plot x\n",
    "plt.imshow(x_debug.numpy()[0, :, :], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "regulation-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "immune-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "yp_all = []\n",
    "for _ in range(1000):\n",
    "#     z_debug = cvae.sampling(torch.Tensor([[0] * z_dim]), torch.Tensor([[0] * z_dim]))  # from prior, z dim = 2\n",
    "#     # print(z_debug)\n",
    "#     yp_debug = cvae.decoder(x=x_debug.view(-1, 784), z=z_debug)\n",
    "    # print(yp_debug.exp())\n",
    "    yp_debug, mu_p, log_var_p = cvae.inference(x=x_debug.view(-1, 784))\n",
    "    yp_all.append(yp_debug.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accessible-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0, count 0/1000\n",
      "Class 1, count 0/1000\n",
      "Class 2, count 836/1000\n",
      "Class 3, count 160/1000\n",
      "Class 4, count 4/1000\n",
      "Class 5, count 0/1000\n",
      "Class 6, count 0/1000\n",
      "Class 7, count 0/1000\n",
      "Class 8, count 0/1000\n",
      "Class 9, count 0/1000\n"
     ]
    }
   ],
   "source": [
    "for class_label in range(10):\n",
    "    print(\"Class {}, count {}/{}\".format(class_label, yp_all.count(class_label), len(yp_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "polish-letter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0331, 0.1042, 0.2068, 0.1577, 0.1473, 0.0580, 0.0567, 0.1025, 0.0791,\n",
       "         0.0547]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp_debug.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-cover",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "painful-reading",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 1000/1000 [00:27<00:00, 35.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# check how many example predicts bimodal distribution\n",
    "# training\n",
    "\n",
    "n_sample = 100\n",
    "n_datapoint = 1000\n",
    "\n",
    "p_all = []\n",
    "\n",
    "for _ in tqdm(range(n_datapoint)):\n",
    "    idx = random.randint(a=0, b=len(train_dataset)-1)\n",
    "    x_debug, y_debug = train_dataset[idx]\n",
    "\n",
    "    yp_all = []\n",
    "    for _ in range(n_sample):\n",
    "#         z_debug = cvae.sampling(torch.Tensor([[0] * z_dim]), torch.Tensor([[0] * z_dim]))  # from prior, z dim = 2\n",
    "#         # print(z_debug)\n",
    "#         yp_debug = cvae.decoder(x=x_debug.view(-1, 784), z=z_debug)\n",
    "        # print(yp_debug.exp())\n",
    "        yp_debug, mu_p, log_var_p = cvae.inference(x=x_debug.view(-1, 784))\n",
    "        yp_all.append(yp_debug.argmax().item())\n",
    "    # calculation percent times the top hit class was predicted\n",
    "    class_count = [yp_all.count(class_label) for class_label in range(10)]\n",
    "    # entropy\n",
    "    p_all.append(entropy(np.asarray(class_count)/n_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wireless-psychology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 98.,  94., 122., 231., 170., 143., 100.,  26.,  12.,   4.]),\n",
       " array([0.        , 0.1718072 , 0.3436144 , 0.51542159, 0.68722879,\n",
       "        0.85903599, 1.03084319, 1.20265038, 1.37445758, 1.54626478,\n",
       "        1.71807198]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "valuable-winter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 1000/1000 [00:27<00:00, 36.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# check how many example predicts bimodal distribution\n",
    "# testing\n",
    "\n",
    "n_sample = 100\n",
    "n_datapoint = 1000\n",
    "\n",
    "p_all = []\n",
    "\n",
    "for _ in tqdm(range(n_datapoint)):\n",
    "    idx = random.randint(a=0, b=len(test_dataset)-1)\n",
    "    x_debug, y_debug = test_dataset[idx]\n",
    "\n",
    "    yp_all = []\n",
    "    for _ in range(n_sample):\n",
    "#         z_debug = cvae.sampling(torch.Tensor([[0] * z_dim]), torch.Tensor([[0] * z_dim]))  # from prior, z dim = 2\n",
    "#         # print(z_debug)\n",
    "#         yp_debug = cvae.decoder(x=x_debug.view(-1, 784), z=z_debug)\n",
    "        # print(yp_debug.exp())\n",
    "        yp_debug, mu_p, log_var_p = cvae.inference(x=x_debug.view(-1, 784))\n",
    "        yp_all.append(yp_debug.argmax().item())\n",
    "    # calculation percent times the top hit class was predicted\n",
    "    class_count = [yp_all.count(class_label) for class_label in range(10)]\n",
    "    # entropy\n",
    "    p_all.append(entropy(np.asarray(class_count)/n_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "flexible-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 78.,  93., 130., 202., 185., 146., 114.,  39.,  10.,   3.]),\n",
       " array([0.        , 0.16682787, 0.33365575, 0.50048362, 0.6673115 ,\n",
       "        0.83413937, 1.00096725, 1.16779512, 1.33462299, 1.50145087,\n",
       "        1.66827874]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "beautiful-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([0.5, 0.5, 0, 0, 0, 0, 0, 0, 0, 0])  # this is what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-response",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-sussex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "emerging-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(0, 10, (10,)).reshape([2, 5])\n",
    "one_hot = torch.nn.functional.one_hot(target, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "removable-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 8, 1, 9, 0],\n",
       "        [4, 4, 4, 0, 7]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "global-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "progressive-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "responsible-orange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-yield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
