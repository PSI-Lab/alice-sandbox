{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "greenhouse-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils.utils_model as us1\n",
    "from model_utils.util_s1_long_seq_bb_method import predict_long_seq_wrapper\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-affiliation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innovative-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_joined_df(df1, df2):\n",
    "    \n",
    "    def check_arr_eq(arr1, arr2):\n",
    "        arr1 = np.sort(np.asarray(arr1))\n",
    "        arr2 = np.sort(np.asarray(arr2))\n",
    "        np.testing.assert_array_almost_equal(arr1, arr2)\n",
    "    \n",
    "    df_check = pd.merge(df1, pd.DataFrame(df2), on=['bb_x', 'bb_y', 'siz_x', 'siz_y'], how='outer')\n",
    "    assert len(df1) == len(df2)\n",
    "    assert len(df1) == len(df_check)\n",
    "    \n",
    "    for _, row in df_check.iterrows():\n",
    "        if 'prob_sm_x' in row.keys() and 'prob_sm_y' in row.keys():\n",
    "            check_arr_eq(row['prob_sm_x'], row['prob_sm_y'])\n",
    "        if 'prob_sl_x' in row.keys() and 'prob_sl_y' in row.keys():   \n",
    "            check_arr_eq(row['prob_sl_x'], row['prob_sl_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-floating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clinical-chapel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading know version v1.0 with params {'num_filters': [32, 32, 64, 64, 64, 128, 128], 'filter_width': [9, 9, 9, 9, 9, 9, 9], 'dropout': 0.0}\n"
     ]
    }
   ],
   "source": [
    "predictor_s1 = us1.Predictor('v1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "declared-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len 200\n",
    "# seq = 'ACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGCGACGACAGCGATGATGGCGATAAAATTAGGCGCTAGCCCGGATGGAGGGGGAGGAGGAACCCCCTCTGATGCTGATGATCGATATGGCGATAAAATTAGGCGCTAGCCCGGATGGAGGGGGAGGAGGAACCCCCTCTGATGCTGATGATCGAT'\n",
    "\n",
    "\n",
    "# # len 56\n",
    "# seq = 'ACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# # len 80\n",
    "# seq = 'ACGATGACGATAGACGCGTATTAGACGAGACGGACGTAGACGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# # len 60\n",
    "# seq = 'ACGATGACGATAGAAGCACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGA'\n",
    "\n",
    "# len 112\n",
    "seq = 'ACGATGACGATAGACGCGACGACACGATGACGATAGACGCGACGACAGCGATGACGATGACGATAGACGACGACAGCGAAGCGATGACGATGACGATAGACGACGACAGCGA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerical-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-vietnam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "european-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/work/psi-lab-sandbox/meetings/2021_02_02/model_utils/utils_model.py:952: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yp = self.model(torch.tensor(de.x_torch))\n"
     ]
    }
   ],
   "source": [
    "# non-split (original interface)\n",
    "stem_1, iloop_1, hloop_1 = predictor_s1.predict_bb(seq, threshold=0.1, topk=1, perc_cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-young",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "simple-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input region: 0-112, 0-112\n",
      "Output region: 0-100, 0-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/work/psi-lab-sandbox/meetings/2021_02_02/model_utils/utils_model.py:837: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yp = self.model(torch.tensor(de.x_torch))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting array output range: 0-100, 0-100\n",
      "Input region: 0-112, 72-112\n",
      "Output region: 0-100, 100-112\n",
      "Selecting array output range: 0-100, 28-40\n",
      "Input region: 72-112, 0-112\n",
      "Output region: 100-112, 0-100\n",
      "Selecting array output range: 28-40, 0-100\n",
      "Input region: 72-112, 72-112\n",
      "Output region: 100-112, 100-112\n",
      "Selecting array output range: 28-40, 28-40\n"
     ]
    }
   ],
   "source": [
    "# split (long sequence interface, array method)\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=28, trim_size=28)\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=40, trim_size=28)\n",
    "\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=80, trim_size=28)\n",
    "\n",
    "# stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "#                                                          patch_size=30)\n",
    "\n",
    "stem_2, iloop_2, hloop_2 = predictor_s1.predict_bb_split(seq, threshold=0.1, topk=1, perc_cutoff=0, \n",
    "                                                         patch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not working for now, see README\n",
    "\n",
    "# # split (long sequence interface, bounding box method)\n",
    "# stem_3, iloop_3, hloop_3 = predict_long_seq_wrapper(seq, patch_size=100, predictor_s1=predictor_s1, \n",
    "#                                                     threshold=0.1, topk=1, perc_cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-leone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-failure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "progressive-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33\n"
     ]
    }
   ],
   "source": [
    "# print(len(stem_1), len(stem_2), len(stem_3))\n",
    "print(len(stem_1), len(stem_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ranging-soundtrack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 99\n"
     ]
    }
   ],
   "source": [
    "# print(len(iloop_1), len(iloop_2), len(iloop_3))\n",
    "print(len(iloop_1), len(iloop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amended-mineral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 12\n"
     ]
    }
   ],
   "source": [
    "# print(len(hloop_1), len(hloop_2), len(hloop_3))\n",
    "print(len(hloop_1), len(hloop_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prescription-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(stem_1), pd.DataFrame(stem_2))\n",
    "# check_joined_df(pd.DataFrame(stem_1), pd.DataFrame(stem_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "announced-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(iloop_1), pd.DataFrame(iloop_2))\n",
    "# check_joined_df(pd.DataFrame(iloop_1), pd.DataFrame(iloop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moved-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_joined_df(pd.DataFrame(hloop_1), pd.DataFrame(hloop_2))\n",
    "# check_joined_df(pd.DataFrame(hloop_1), pd.DataFrame(hloop_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-timber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-substitute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impossible-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respiratory-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# de = us1.SeqPairEncoder(seq_1, seq_2)\n",
    "de = us1.DataEncoder('ACGT')\n",
    "yp = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "completed-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6912e-04, 9.7935e-05, 1.0809e-03, 2.5290e-02],\n",
       "        [9.7002e-05, 1.0694e-04, 5.3612e-03, 1.3337e-02],\n",
       "        [6.5571e-04, 2.1104e-03, 2.2309e-02, 6.3060e-02],\n",
       "        [3.2504e-03, 2.5612e-03, 1.9993e-02, 1.4175e-02]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp['stem_on'][0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abstract-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "de = us1.DataEncoder('NNACGT')\n",
    "yp2 = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thorough-lebanon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0001, 0.0013, 0.0010, 0.0088],\n",
       "        [0.0009, 0.0027, 0.0013, 0.0021],\n",
       "        [0.0004, 0.0033, 0.0012, 0.0026],\n",
       "        [0.0030, 0.0008, 0.0019, 0.0020]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp2['stem_on'][0, 0, 2:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-freight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-dayton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alive-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicegao/anaconda2/envs/yeast_d_cell/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "de = us1.SeqPairEncoder('ACGT', 'AAACGT')\n",
    "# de = us1.DataEncoder('ACGT')\n",
    "yp = predictor_s1.model(torch.tensor(de.x_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-brand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-eating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
