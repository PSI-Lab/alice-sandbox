{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgutils.pandas as dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils.utils_model import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_utils.utils_s2 as us2 # TODO merge s2 util\n",
    "from model_utils.utils_nn_s2 import predict_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to util\n",
    "def stem2db_str(df_stem, seq_len):\n",
    "    bracket_pairs = cycle([('(', ')'), ('[', ']'), ('{', '}')])\n",
    "    \n",
    "    db_str = ['.'] * seq_len\n",
    "    for _, row in df_stem.iterrows():\n",
    "        bb_x = int(row['bb_x'])\n",
    "        bb_y = int(row['bb_y'])\n",
    "        siz = int(row['siz_x'])\n",
    "        siz_y = int(row['siz_y'])\n",
    "        assert siz == siz_y\n",
    "        bracket_pair = next(bracket_pairs)  # py3\n",
    "        for i in range(siz):\n",
    "            db_str[bb_x+i] = bracket_pair[0]\n",
    "            db_str[bb_y-i] = bracket_pair[1]\n",
    "    return ''.join(db_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to util\n",
    "def stem2arr(df_stem, seq_len, flatten_triu=True):\n",
    "    x = np.zeros((seq_len, seq_len))\n",
    "    for _, row in df_stem.iterrows():\n",
    "        bb_x = int(row['bb_x'])\n",
    "        bb_y = int(row['bb_y'])\n",
    "        siz = int(row['siz_x'])\n",
    "        siz_y = int(row['siz_y'])\n",
    "        assert siz == siz_y\n",
    "        for i in range(siz):\n",
    "            i1 = bb_x+i\n",
    "            i2 = bb_y-i\n",
    "            # FIXME should not happen! s1 inference should prune these\n",
    "            if i1 < 0 or i1 >= seq_len or i2 <0 or i2 >= seq_len:\n",
    "                print(\"Skip out-of-range base-pair {}-{}\".format(i1, i2))\n",
    "                continue\n",
    "            x[i1, i2] = 1\n",
    "            x[i2, i1] = 1\n",
    "    # extract upper triangle and flatten if option is set, useful for evaluation\n",
    "    if flatten_triu:\n",
    "        return x[np.triu_indices(seq_len)]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(seq_len, df_pred, bounding_boxes, convert_tl_to_tr=True):\n",
    "    \n",
    "    def perf_measure(y_actual, y_hat):\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "\n",
    "        for i in range(len(y_hat)): \n",
    "            if y_actual[i]==y_hat[i]==1:\n",
    "                TP += 1\n",
    "            elif y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "                FP += 1\n",
    "            elif y_actual[i]==y_hat[i]==0:\n",
    "                TN += 1\n",
    "            elif y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "                FN += 1\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "        return TP, FP, TN, FN\n",
    "    \n",
    "    df_target_stem, df_target_iloop, df_target_hloop = evaluator.make_target_bb_df(bounding_boxes, convert_tl_to_tr=True)\n",
    "    x_pred = stem2arr(df_pred[df_pred['bb_type'] == 'stem'], seq_len, flatten_triu=True)\n",
    "    x_target = stem2arr(df_target_stem, seq_len, flatten_triu=True)\n",
    "    \n",
    "    TP, FP, TN, FN = perf_measure(x_target, x_pred)\n",
    "    \n",
    "    sensitivity = float(TP)/(TP+FN)\n",
    "    ppv = float(TP)/(TP+FP)\n",
    "    return sensitivity, ppv\n",
    "    \n",
    "#     report_dict = classification_report(x_target, x_pred, output_dict=True)\n",
    "#     raise ValueError\n",
    "    \n",
    "    # in binary classification, recall of the positive class is \n",
    "    # also known as “sensitivity”; recall of the negative class is “specificity”.\n",
    "#     return report_dict[1]['recall']\n",
    "#     return report_dict['weighted avg']['precision'], report_dict['weighted avg']['recall'], report_dict['weighted avg']['f1-score'], report_dict['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ss_graph(df_stem, seq):\n",
    "    G = nx.Graph()\n",
    "    nodes = []\n",
    "    for i, base in enumerate(seq):\n",
    "        nodes.append((i, {\"label\": base}))\n",
    "    G.add_nodes_from(nodes)\n",
    "    # backbone\n",
    "    for i in range(len(seq)-1):\n",
    "        G.add_edge(i, i+1)\n",
    "    # hydrogen bonds\n",
    "    for _, row in df_stem.iterrows():\n",
    "        bb_x = int(row['bb_x'])\n",
    "        bb_y = int(row['bb_y'])\n",
    "        siz = int(row['siz_x'])\n",
    "        siz_y = int(row['siz_y'])\n",
    "        assert siz == siz_y\n",
    "        for i in range(siz):\n",
    "            G.add_edge(bb_x+i,bb_y-i)\n",
    "    return G\n",
    "#     G.add_edge(1,2)\n",
    "#     G.add_edge(1,3)\n",
    "#     nx.draw(G, with_labels=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_s2 = us2.Predictor('v0.2')\n",
    "\n",
    "# predictor_s2 = us2.Predictor('s2_training/result/synthetic_s2_5000/model_ckpt_ep_34.pth')\n",
    "\n",
    "predictor_s2 = us2.Predictor('v0.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../2021_01_12/data/synthetic_s1_pred_1000_t0p1_k1.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(predictor=None)   # using static utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_row(seq, bb_stem, bb_iloop, bb_hloop):\n",
    "    uniq_stem = pd.DataFrame(bb_stem)\n",
    "    uniq_iloop = pd.DataFrame(bb_iloop)\n",
    "    uniq_hloop = pd.DataFrame(bb_hloop)\n",
    "    df_pred = predict_wrapper(uniq_stem, uniq_iloop, uniq_hloop, \n",
    "                              discard_ns_stem=True, min_hloop_size=2, \n",
    "                              seq=seq, m_factor=1, predictor=predictor_s2)\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "df = dgp.add_column(df, 'df_pred', ['seq', 'bb_stem', 'bb_iloop', 'bb_hloop'], pred_row, pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "df = dgp.add_columns(df, ['sensitivity', 'ppv'], \n",
    "                     ['len', 'df_pred', 'bounding_boxes'], \n",
    "                     # setting convert_tl_to_tr to True since this particular dataset's ground truth is in old format\n",
    "                     lambda seq_len, df_pred, bounding_boxes: compute_metrics(seq_len, df_pred, bounding_boxes, convert_tl_to_tr=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.scatter(df, x='sensitivity', y='ppv',\n",
    "          marginal_x='violin', marginal_y='violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience\n",
    "\n",
    "def print_db_str(seq, bounding_boxes, df_pred):\n",
    "    df_target_stem, df_target_iloop, df_target_hloop = evaluator.make_target_bb_df(bounding_boxes, convert_tl_to_tr=True)\n",
    "    \n",
    "    print('>s1')\n",
    "    print(seq)\n",
    "    db_str_target = stem2db_str(df_target_stem, len(seq))\n",
    "    print(db_str_target)\n",
    "\n",
    "    print('>s2')\n",
    "    print(seq)\n",
    "    db_str_pred = stem2db_str(df_pred[df_pred['bb_type'] == 'stem'], len(seq))\n",
    "    print(db_str_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find example with various metric\n",
    "\n",
    "# top: sensitivity == ppv == 1\n",
    "row = df[(df['sensitivity'] == 1) & (df['ppv']==1)].sample().iloc[0]\n",
    "print_db_str(row['seq'], row['bounding_boxes'], row['df_pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high: sensitivity >= 0.9, ppv >= 0.9 (but != 1)\n",
    "row = df[(df['sensitivity'] >= 0.9) & (df['sensitivity'] != 1) & (df['ppv'] >= 0.9) & (df['ppv'] != 1)].sample().iloc[0]\n",
    "print_db_str(row['seq'], row['bounding_boxes'], row['df_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mid: 0.4 - 0.6\n",
    "row = df[(df['sensitivity'] >= 0.4) & (df['sensitivity'] < 0.6) & (df['ppv'] >= 0.4) & (df['ppv'] < 0.6)].sample().iloc[0]\n",
    "print_db_str(row['seq'], row['bounding_boxes'], row['df_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low: < 0.1\n",
    "row = df[(df['sensitivity'] < 0.1) & (df['ppv'] < 0.1)].sample().iloc[0]\n",
    "print_db_str(row['seq'], row['bounding_boxes'], row['df_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = display_ss_graph(df_pred[df_pred['bb_type'] == 'stem'], seq)\n",
    "nx.draw(G, with_labels=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
