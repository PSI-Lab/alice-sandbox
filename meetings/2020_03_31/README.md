

## Paper review

### ShaKer: RNA SHAPE prediction using graph kernel

Paper: https://academic.oup.com/bioinformatics/article/35/14/i354/5529262

Github: https://github.com/BackofenLab/ShaKer

The authors trained a model to predict SHAPE accessibility from RNA structures generated by RNAfold.
Abstract says "based on sequence input only" which is a bit confusing,
since they still rely on RNAfold to generate the structures.

- At training time, they used RNAfold to generate one MFE structure per each sequence,
encoded the MFE structure as a graph, then applied a graph kernel to compute one feature vector per each node.

- Training dataset: ribosomal RNA? From sukosd?

- Testing dataset: Deigan 2009, Hajdin 2013, Monstaseri 2017.

- They used gradient tree boosting to predict per-base accessibility from the above feature vector.

- At test time, an ensemble of structures is generated, and per-base prediction is made for each structure,
and the final per-base prediction is computed as the above weighted by the Boltzmann probability of the corresponding strutcure.
It was unclear why they did this at test time, because their model was only trained using MFE structures as input.

- In Fig.3, when evaluating the model performance, they treated
RNAplfold-assited by SHAPE data as the ground truth,
which would clearly give any RNAfold-based model (their model) an advantage.

- In Fig.3, it looks like the reference structure accounts for most of the observed structures,
as indicated by the correlation between reference structure derived binary accessibility,
and the 'ground truth'.

- No supplementary available, couldn't details on how the model was trained.
For example, did they run RNAfold on the full-length sequence? Some ribosomal RNA can be a few thousand bases long.
Looks like they've checked in the training scripts to GitHub: https://github.com/BackofenLab/ShaKer/blob/master/shaker/simushape.py
Didn't bother going through the code.

- Some data they used might come in handy (should include both training and testing): https://github.com/BackofenLab/ShaKer/tree/master/data

- They mentioned one way to compare one structure to an ensemble,
as introduced by Lange 2012. It's just the sum of base-pair probabilities.
Not sure how good of a metric this is.


### Evaluating the accuracy of SHAPE-directed RNA secondary structure predictions

Paper: https://academic.oup.com/nar/article/41/5/2807/2414458

This paper evaluate the effect of different types of simulated SHAPE data on
the accuracy of SHAPE-direct (soft constraint) thermodynamic folding.

- The so-called "stochastic model" is a conditional distribution of the observed SHAPE reactivity,
where they've introduced 3 ways of doing the conditioning:
(1) no conditioning, i.e. global distribution, (2) paired/unpaired, (3) stacked/helix-end/unpaired.
Distribution was fitted on the observed empirical distribution from the training dataset.
This "model" was used to simulate SHAPE reactivity data on each given sequence-structure pair (1000 trials).

- One implicit+strong assumption they made in the paper is that,
for a given structure, there is one "ground truth" structure,
and the observed stochasticity in SHAPE reactivity is just a result of measurement noise,
which is what their "stochastic model" is trying to capture.

- They used a set of fixed parameters to convert SHAPE reactivity to pseudo-free energy term.

- Training dataset: E. coli ribosomal sequences 16S (1542nt) and 23S (2904nt) with known structure
(from Comparative RNA Web) and measured SHAPE reactivity (from personal communication?).

- Testing dataset: 16S/18S ribosomal sequences with known structure (from Comparative RNA Web).

- Result in Table 1 should be considered "training performance",
since E. coli 16S was used to estimate the conditional distribution.
Although it probably didn't fully overfit to this data since the "model" did not have many parameters.
Above is also evident from Figure 2, where E. coli has the biggest improvement (y-x).

- Their overall conclusion is that,
the higher MFE accuracy, the more similarity between the SHAPE-directed-folded structure and the MFE structure,
and the higher the SHAPE-directed-folded structure accuracy (again, by comparing to one "ground truth" structure).
They also observed that, majority of the paired bases in MFE, are consistently paired/unpaired in all 1000 trials.

- Their data link is dead: https://users-birc.au.dk/~zs/SHAPEsimulations/

## Data-directed RNA secondary structure prediction using probabilistic modeling

Deng 2016

Paper: https://rnajournal.cshlp.org/content/22/8/1109.full

GetHub : https://github.com/AviranLab/RNAprob

This paper follows "Evaluating the accuracy of SHAPE-directed RNA secondary structure predictions",
and their main contribution is replacing the empirical conditional distribution (reactivity given structural context),
with parameterized distribution. Some analysis and insights are interesting and worth mention.

- Basic assumption and problem formulation stays the same:
In order to do SHAPE-directed folding,
we want to estimate the reactivity distribution conditioned on local structural context,
this is done by looking at a set of sequences with known structure and SHAPE values.

- Dataset: 23 sequence+structure+SHAPE from various studies, length 34-2904nt, see supplementary table S1

- Analysis setup: (1) estimate reactivity distribution, where the condition can be one of those in "Evaluating the accuracy of SHAPE-directed RNA secondary structure predictions",
(2) simulate SHAPE data using the real structure and the estimated distribution,
(3) thermodynamic folding with pesudo free energy added, where the pseudo free energy term is also conditional on
local structure context (some needs to be back-traced during dynamic programming).

- Best performance is achieved when the estimation assumption (step 3 above) matches the generation assumption (step 1 above).

- High reactivity (top 20% percentile) data points are the major driver for performance improvement,
accouts for 60%-80% of the total performance gain. This is
followed by low reactivity points (bottom 20%). The two combined accounts for ~90% of the performance gain.
Data points with intermediate reactivity do not contribute much.

- Authors mentioned that "while probing data measure local structural constraints,
they only indirectly report base-pairing probabilities".
TODO check refs: Ochsenreiter 2015, Sloma 2015



### ï»¿RNA SECONDARY STRUCTURE PREDICTION BY LEARNING UNROLLED ALGORITHMS

End-to-end model by expression constraints as convex optimization,
and unroll the algorithm with fixed number of steps to calculate gradient.


## Data processing

### Dataset used in E2Efold

Author published the pickled dataset,
had to hack to load since they've pickled an undefined object (read through their github code to reconstruct the obj).

Their processed data was padded to max length.... does that mean

Processed to our internal format,
with two columns: seq (ACGU characters) & one_idx (list of tuple for location of 1's in pair-matrix).

See https://github.com/PSI-Lab/alice-sandbox/tree/d1897e72777fbfffb34c1cbbab2712620ae3910a/rna_ss/data_processing/e2efold
for workflow and uploaded data DC IDs.

TODO some data points seem to have incompatible sequence length and matrix index... needs debugging.

## Pytorch training setup

See [rna_ss/](rna_ss/).

Performance on simulated dataset (10 epoch run):

```
training loss (running) 55.66516876220703, au-ROC 0.9968286654065224, au-PRC 0.7006910216709833
validation loss 55.66516876220703, au-ROC 0.996820095065758, au-PRC 0.7015527064883957
```

## TODOs

- train & evaluate on E2Efold dataset

- CVAE?








