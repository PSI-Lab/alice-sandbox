# 2020-01-31


## Paper "﻿RNA folding with hard and soft constraints"

﻿- discussed principled way to incorporate hard and soft constraints into DP

- does not seem to solve the generalization problem (i.e. predict on novel sequences)

- talked about "assisted folding" - RNApvmin?

- only went through the paper briefly, didn't read the detailed formulations

- more notes in Mendeley

## RNApvmin

- Calculate a perturbation vector that minimizes discripancies between predicted and observed pairing probabilities


Define sequence in `sequence.fasta` and shape reactivity in `sequence.shape`, run:
```
RNApvmin sequence.shape < sequence.fasta > sequence.pv
```
the output `sequence.pv` is the purturbation vector (one value per base, not sure the exactly meaning?),
which can be fed into RNAfold:
```
RNAfold --shape=sequence.pv --shapeMethod=W < sequence.fasta
```

See [rnapvmin/](rnapvmin/) (note that the toy example seems to result in all 0's in the perturbation vector...).


## RNA NN paper

- pre-training dataset: bpRNA, >100,000 RNA sequences, from comparative study.
Removing redundant sequences at 80% cutoff: 13,419 sequences.

- fine-tuning dataset: 120 + 30 + 67 sequences

- didn't fix any weights when fine-tuning

- test dataset 1: 62 sequence, test dataset 2: 39 + 6 sequences

- From looking at the code, the output is generated by simply thresholding
(so there might also be triplets)

- From the related protein paper, 2D-BLSTM seems to be two independent BLSTMs, one running horizontally, one vertically



## RNA NN code

- https://github.com/jaswindersingh2/SPOT-RNA/

conda create -n spot_rna python=3.6 anaconda

In `get_data`:

one_hot: mapping to 1-hot encoding, order: AUCG

z_mask: LxL matrix with lower triangular+2 set to 0, others 1

l_mask: same as z_mask, but setting rows/cols corresponding to non-AUCG bases to 0

feature is LxLx8 encoding where 8-ch at location (i,j) corresponding to the concatenation of encoded base i and j

return data is flatten-ed (list comprehension is just for converting array to list)

also return data last 2 values are identical?


In `SPOT-RNA.py`:

there is a try-except block for running predictor, when does it fail?

out[1] is the name of sequence (string)

I guess internally the LSTM is being run in 'testing' mode.
how long is the path? L^2/2???? (guessed from the way they flatten the data)
need to look at their training code (or read the other paper (protein)).
Update: read the protein paper (TODO title) they are running two BLSTMs,
one horizontal one vertical with output concatenated.
Still not super clear how they generated the final output?

It doesn't seem that they can generate stochastic output in the recurrent manner. <- not 100% sure until I see the actual training code.

element-wise taking mean from all models `ensemble_outputs[i] = np.mean(outputs[i],0)`

`prob_to_secondary_structure(ensemble_outputs[i], mask[i], sequences[i], i, args)`
mask[i] is the z_mask/l_mask matrix

In `prob_to_secondary_structure`:

`mask = output_mask(seq)` hard-coded list of allowed pairs, default seems to be allowing all 16 pairs.

`y_pred` is maps the linear output `ensemble_outputs[i]` back to the upper triangle.

`pred_pairs = [i for I, i in enumerate(seq_pairs) if outputs_T[I]]` select pairs whose prediction is

In `multiplets_free_bp(pred_pairs, y_pred):`:
dealing with multi-pairing (more than 2 bases)?

`tertiary_bp` is only used for plot



Constructed short sequence as an experiment:

```
>short_seq
CGGUUUACCG
```




## Toy dataset

still in progress.

## Graph NN & system bio

Had a meeting with Amir and Andrew.

yeast?

## Ideas


- evaluate my model on their test set (how to generate one structure?)

- conv filter visualization (before inner product)

- 0.25/0.75 encoding

- add non-recurrent target

- random recurrent directions






