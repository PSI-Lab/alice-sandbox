{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import PredictorSPlitModel, arr2db, forna_url, DataEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on CPU is extremely slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alice/work/psi-lab-sandbox/rna_ss/model/rnafold_mini_data_2d_ar_2/model.py:133: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
      "\n",
      "4\n",
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model missing names layers, will try to infer (unreliable!).\n",
      "utils.py:366: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  output=[layer_final_hidden.output, layer_fe.output])\n",
      "utils.py:376: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ar..., inputs=[<tf.Tenso...)`\n",
      "  output=new_output)\n"
     ]
    }
   ],
   "source": [
    "# model = Predictor('model/2019_09_08.1/model.hdf5')\n",
    "model = PredictorSPlitModel('model/2019_09_12.1/model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [00:01<00:11,  2.48it/s]utils.py:483: RuntimeWarning: divide by zero encountered in log\n",
      "  _lp = vals_sampled * np.log(_vals) + (1 - vals_sampled) * np.log(1 - _vals)\n",
      "100%|██████████| 32/32 [00:09<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "seq='GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU'\n",
    "# y, logp, fe = model.predict_one_step_ar(seq=seq, \n",
    "#                                        n_sample=100, start_offset=2, p_clip=1e-12)\n",
    "\n",
    "y, logp, fe = model.predict_one_step_ar(seq=seq, \n",
    "                                       n_sample=20, start_offset=2, p_clip=1e-12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 34, 34, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "0\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "1\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "2\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(3, 15), (4, 14), (5, 12), (6, 11)], [(17, 28), (18, 27)]]\n",
      "[0, 0]\n",
      "3\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=...((((....)).)).((........)).....\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14)], [(7, 32), (8, 31), (9, 30), (10, 29), (11, 28), (12, 27)]]\n",
      "Pseudoknot detected.\n",
      "[1, 0]\n",
      "4\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=[[[[[..((((((.]]]]]........)))))).\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "5\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(3, 15), (4, 14), (5, 12), (6, 11)], [(17, 28), (18, 27)]]\n",
      "[0, 0]\n",
      "6\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=...((((....)).)).((........)).....\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "7\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "8\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "9\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "10\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(16, 29), (17, 28), (18, 27)]]\n",
      "[0]\n",
      "11\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=................(((........)))....\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "12\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "13\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "14\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(3, 15), (4, 14), (5, 12), (6, 11)], [(17, 28), (18, 27)]]\n",
      "[0, 0]\n",
      "15\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=...((((....)).)).((........)).....\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "16\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(3, 15), (4, 14), (5, 12), (6, 11)], [(17, 28), (18, 27)]]\n",
      "[0, 0]\n",
      "17\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=...((((....)).)).((........)).....\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "18\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n",
      "[[(0, 18), (1, 17), (2, 16), (3, 15), (4, 14), (5, 12), (6, 11)]]\n",
      "[0]\n",
      "19\n",
      "http://nibiru.tbi.univie.ac.at/forna/forna.html?id=url/name&sequence=GGCGCAGUGGGCUAGCGCCACUCAAAAGGCCCAU&structure=(((((((....)).)))))...............\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_strs = []  # collect all dot bracket notation\n",
    "\n",
    "for idx_sample in range(y.shape[0]):  \n",
    "    _pred = y[idx_sample, :, :, 0]\n",
    "\n",
    "#     print idx_sample\n",
    "#     print np.where(_pred==1)\n",
    "    \n",
    "#     # locate pseudo knot?\n",
    "#     one_idxes = zip(np.where(_pred==1)[0], np.where(_pred==1)[1])\n",
    "#     for i in range(len(one_idxes)):\n",
    "#         for j in range(i+1, len(one_idxes)):\n",
    "#             pair1 = one_idxes[i]\n",
    "#             pair2 = one_idxes[j]\n",
    "#             # see if they cross\n",
    "#             if pair2[0] < pair1[1] < pair2[1]:\n",
    "#                 print 'knot!'\n",
    "#                 print pair1, pair2\n",
    "    \n",
    "\n",
    "    \n",
    "    # dot-bracket notation\n",
    "    db_str = arr2db(_pred)\n",
    "    db_strs.append(db_str)\n",
    "#     print idx_sample, db_str\n",
    "    print idx_sample\n",
    "    print forna_url(seq, db_str)\n",
    "    \n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_org:0\", shape=(?, ?, 4), dtype=float32)\n",
      "Tensor(\"ar_label/Sigmoid:0\", shape=(?, ?, ?, 1), dtype=float32)\n",
      "Tensor(\"div:0\", shape=(?, ?, 4), dtype=float32)\n",
      "<keras.backend.tensorflow_backend.Function object at 0x7fe4712a2190>\n",
      "0\n"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients/concatenate_3/concat_grad/Slice}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79ab0b8447e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make sure to pick the index where the current val is 0 to do GA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alicegao/work/psi-lab-sandbox/rna_ss/eval/rnafold_mini_data_2d_ar_2/utils.pyc\u001b[0m in \u001b[0;36mgradient_ascent\u001b[0;34m(self, seq, y_prev, idx1, idx2)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_single\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;31m# loss_value, grads_value = iterate([x_new])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mx_new\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAbortedError\u001b[0m: Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients/concatenate_3/concat_grad/Slice}}]]"
     ]
    }
   ],
   "source": [
    "# make sure to pick the index where the current val is 0 to do GA\n",
    "model.gradient_ascent(seq=seq, y_prev=y[-1, :, :, 0], idx1=7, idx2=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DataEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_org:0\", shape=(?, ?, 4), dtype=float32)\n",
      "Tensor(\"ar_label/Sigmoid:0\", shape=(?, ?, ?, 1), dtype=float32)\n",
      "Tensor(\"div_2:0\", shape=(?, ?, 4), dtype=float32)\n",
      "<keras.backend.tensorflow_backend.Function object at 0x7fe4412efb90>\n",
      "0\n"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients_2/concatenate_3/concat_grad/Slice}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-37877c1018ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_single\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#     loss_value, grads_value = iterate([x_new])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mx_new\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgrads_value\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAbortedError\u001b[0m: Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients_2/concatenate_3/concat_grad/Slice}}]]"
     ]
    }
   ],
   "source": [
    "y_prev=y[-1, :, :, 0]\n",
    "idx1=7\n",
    "idx2=10\n",
    "\n",
    "\n",
    "x_single = DataEncoder.encode_seqs([seq])\n",
    "if len(y_prev.shape) == 2:\n",
    "    y_single = y_prev[np.newaxis, :, :, np.newaxis]\n",
    "elif len(y_prev.shape) == 4:\n",
    "    y_single = y_prev.copy()\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "# z_repr, _ = self.model_repr.predict([x_single, y_single])\n",
    "# y = self.model_ar.predict([z_repr, y_single])\n",
    "# # compute gradient\n",
    "# # layer_output = self.model_ar.layers[-1].output\n",
    "# layer_output = self.model_ar.layers[-1].get_output_at(-1)\n",
    "# loss = kb.mean(layer_output[:, idx1, idx2, :])\n",
    "# input_node = self.model_ar.layers[0].input[0]  # seq input, not y_prev\n",
    "\n",
    "# for this part, we assume the model has named layers\n",
    "y, fe = model._model.predict([x_single, y_single])\n",
    "# input_node = next(l for l in self._model.layers if l.name == 'input_org').input\n",
    "# layer_output = next(l for l in self._model.layers if l.name == 'ar_label').get_output_at(-1)\n",
    "input_node = model._model.input[0]\n",
    "input_node2 = model._model.input[1]\n",
    "layer_output = model._model.output[0]\n",
    "print input_node\n",
    "print layer_output\n",
    "loss = kb.mean(layer_output[:, idx1, idx2, :])\n",
    "# 'input_org'\n",
    "# 'target_prev'\n",
    "# 'ar_label'\n",
    "# 'fe'\n",
    "\n",
    "# grads = kb.gradients(loss, input_node)[0]\n",
    "grads = kb.gradients(loss, model._model.input)[0]\n",
    "grads /= (kb.sqrt(kb.mean(kb.square(grads))) + 1e-5)\n",
    "# iterate = kb.function([input_node, input_node2], [loss, grads])\n",
    "# iterate = kb.function([input_node], [loss, grads])\n",
    "iterate = kb.function(model._model.input, [loss, grads])\n",
    "print grads\n",
    "print iterate\n",
    "\n",
    "x_new = x_single.astype(np.float32)\n",
    "# add a little bit noise\n",
    "x_new += 1e-2\n",
    "# normalize\n",
    "x_new = x_new / np.sum(x_new, axis=-1)[:, :, np.newaxis]\n",
    "# run gradient ascent\n",
    "x_ite = []\n",
    "for i in range(200):\n",
    "    print i\n",
    "    loss_value, grads_value = iterate([x_new, y_single])\n",
    "#     loss_value, grads_value = iterate([x_new])\n",
    "    x_new += grads_value * 0.01\n",
    "    # re-normalize\n",
    "    x_new = x_new / np.sum(x_new, axis=-1)[:, :, np.newaxis]\n",
    "    #     print x1_new\n",
    "\n",
    "    x_ite.append(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 34, 4)\n",
      "(1, 34, 34, 1)\n",
      "(1, 34, 4)\n"
     ]
    }
   ],
   "source": [
    "print x_single.shape\n",
    "print y_single.shape\n",
    "print x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AbortedError",
     "evalue": "Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients_2/concatenate_3/concat_grad/Slice}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f4ae4fbcebf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# iterate([x_single, np.zeros((1, 34, 34, 1))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_single\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alicegao/anaconda2/envs/dg_work_py2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAbortedError\u001b[0m: Operation received an exception:Status: 5, message: could not create a view primitive descriptor, in file tensorflow/core/kernels/mkl_slice_op.cc:433\n\t [[{{node gradients_2/concatenate_3/concat_grad/Slice}}]]"
     ]
    }
   ],
   "source": [
    "# iterate([x_single, np.zeros((1, 34, 34, 1))])\n",
    "iterate([x_single.astype(np.float16), np.zeros((1, 34, 34, 1)).astype(np.float16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.1920929e-07,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [2.8610229e-06, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [4.3064356e-05, 7.4416399e-05, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [2.4762198e-01, 3.9994717e-05, 1.1920929e-07, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-1.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [ 0.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [-1.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         ...,\n",
       "         [-1.],\n",
       "         [-1.],\n",
       "         [-1.]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataEncoder.y_init(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
